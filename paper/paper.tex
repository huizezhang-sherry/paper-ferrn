% !TeX program = pdfLaTeX
\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage{textcomp}
\usepackage[hyphens]{url} % not crucial - just used below for the URL
\usepackage{hyperref}
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%

%% load any required packages here


\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}



\begin{document}


\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if0\blind
{
  \title{\bf Title here}

  \author{
        Author 1 \thanks{The authors gratefully acknowledge \ldots{}} \\
    Department of YYY, University of XXX\\
     and \\     Author 2 \\
    Department of ZZZ, University of WWW\\
      }
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Title here}
  \end{center}
  \medskip
} \fi

\bigskip
\begin{abstract}
\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  check consistency of using PP for projection pursuit and PPI for
  projection pursuit index
\end{enumerate}
\end{abstract}

\noindent%
{\it Keywords:} 3 to 6 keywords, that do not appear in the title
\vfill

\newpage
\spacingset{1.45} % DON'T change the spacing!

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\hypertarget{derivative-free-optimisation}{%
\subsection{Derivative free
optimisation}\label{derivative-free-optimisation}}

Given an objective function \(f\), one way of optimising it is to equate
its gradient to zero. In modern optimisation problems, gradient
information can be hard to evaluate or sometimes even impossible and
Derivative-Free Optimisation (DFO) methods can be useful to approach
these problems. The two most common methods in DFO are
\emph{direct-search methods} and \emph{model-based methods} and this
paper dedicates to the discussion of direct-search methods, which gains
its popularity due to its simplicity in use and reliability in
complicated practical problem. Coined by \citet{hooke1961direct}, direct
search methods don't require any gradient or hessian information and
evaluate \(f\) directly. A well-known example of it is the Nelder-Mead
algorithm \citep{nelder1965simplex} and it enjoys the popularity due to
its simplicity and reliability. {[}feel like this sentence can be
expanded to include more information. xxx{]}. Further, direct search
methods can be classified as \emph{stochastic} and \emph{deterministic}
depends on whether a random sample is used in the search. The stochastic
version of direct-search method is the focus of this paper.

\hypertarget{projection-pursuit-guided-tour}{%
\subsection{Projection pursuit guided
tour}\label{projection-pursuit-guided-tour}}

The optimisation problem we're interested in is in the context of
projection pursuit. Coined by \citet{friedman1974projection}, projection
pursuit is a method that detects the interesting structure
(i.e.~clustering, outliers and skewness) of multivariate data via
projecting it in lower dimensions. A Projection Pursuit Index (PPI) is a
function of the projection matrix (a.k.a projection angle, projection
basis) measuring the ``interestingness'' of data and we refer the value
of PPI function as \emph{index value}. In the literature, the indices
being proposed include lengendre index \citep{friedman1974projection},
hermite index \citep{hall1989polynomial}, natural hermite index
\citep{cook1993projection}, chi-square index
\citep{posse1995projection}, LDA index \citep{lee2005projection} and PDA
index \citep{lee2010projection}. {[}Any literature on holes index?
xxx{]}

As \citet{friedman1974projection} noted ``\ldots{}, the technique use
for maximising the projection index strongly influences both the
statistical and the computational aspects of the procedure.'' A suitable
optimisation procedure is needed to find the projection angle that
maximises the PPI and the quality of the optimisation largely affect the
interesting projections one could possibly observe.

Projection pursuit is usually used in conjunction with a tour method
called \emph{guided tour}. Tour explores the multivariate data
\emph{interactively} via playing a series of projections, that form a
\emph{tour path}, like movie frames in real time. Starting from a
randomly generated projection basis, projection pursuit searches for a
target basis with higher index value and guided tour interpolates
geodesically between the initial basis and the target basis. This series
of bases forms a tour path and the projection of the data on these bases
is played in real time. This search-and-interpolateprocess is repeated
until no basis can be found with higher index value. Modified from
\citet{buja2005computational}, Figure \ref{tour-path} vividly depicts
the tour path in guided tour. Guided tour, along with other types of
tour, has been implemented in the \emph{tourr} package in R, available
on the Comprehensive R Archive Network at
\url{https://cran.r-project.org/web/packages/tourr/}
\citep{wickham2011tourrpackage}.

\begin{figure}
\includegraphics[width=1\linewidth,height=0.6\textheight]{/Users/hzha400/Documents/3.PhD/paper-tour-vis/figures/tour_path_increasing} \caption{\label{tour-path}An illustration of the tour path}\label{fig:tour-path}
\end{figure}

{[}doubt if I need the following. xxx{]}

\hypertarget{optimisation-in-projection-pursuit}{%
\subsection{Optimisation in projection
pursuit}\label{optimisation-in-projection-pursuit}}

Below listed several features characterise the optimisation procedures
needed in projection pursuit

\begin{itemize}
\item
  \emph{Being able to handle non-differentiable PPI function}: The PPI
  function could be non-differentiable, thus derivative free methods are
  preferred.
\item
  \emph{Being able to optimise with constraints}: The constraint comes
  from projection matrix being an orthonormal matrix.
\item
  \emph{Being able to find both local and global maximum}: Although the
  primary interest is to find the global maximum, local maximum could
  also reeal structures in the data that are of our interest.
\end{itemize}

{[}thinking if the following three should be presented as algorithms or
plain description is fine. xxx{]}

There are three existing methods for optimisating PPI function and we
review them below. \citet{posse1995projection} used a stochastic direct
search method, a random search algorithm to sample new bases in the
neighbourhood of the current basis defined by the radius of the
p-dimensional sphere, \(c\). The new basis is taken as the target basis
if it has higher index value, or the sampling continues. If no basis is
found to have higher index value after a certain number of tries \(n\),
the radius \(c\) is halved. The algorithm stops when the maximum number
of iteration is attained or the radius \(c\) is less than a
pre-determined number.

\citet{cook1995grand} explained the use of a gradient ascent
optimisation with the assumption that the index function is continuous
and differentiable. Since some indices could be non-differentiable, the
computation of derivative is replaced by a pseudo-derivative of
evaluating five randomly generated directions in a tiny nearby
neighbourhood. Taking a step on the straight derivative direction has
been modified to maximise the projection pursuit index along the
geodesic direction.

Simulated annealing
\citep[\citet{kirkpatrick1983optimization}]{bertsimas1993simulated} is a
non-derivative procedure based on a non-increasing cooling scheme
\(T(i)\). Given an initial \(T_0\), the temperature at iteration \(i\)
is defined as \(T(i) = \frac{T_0}{log(i + 1)}\). The simulated annealing
algorithm works as follows. Given a neighbourhood parameter \(\alpha\)
and a randomly generated orthonormal basis \(B\), a candidate basis is
constructed as \(B_j = (1- \alpha)B_i + \alpha B\) where \(B_i\) is the
current basis. If the index value of the candidate basis is larger than
the one of the current basis, the candidate basis becomes the target
basis. If it is smaller, the candidate is accepted with probability
\(A = \min \left(\exp(-\frac{I(B_j) - I(B_i)}{T(i)}), 1 \right)\) where
\(I(.)\) is the index function.

\hypertarget{problems-and-difficulties-in-pp-optimisation}{%
\subsection{problems and difficulties in PP
optimisation}\label{problems-and-difficulties-in-pp-optimisation}}

Below listed several issues in projection pursuit optimisation. Some are
general optimisation problems, while others are more specific for PP
optimisation.

\begin{itemize}
\item
  \emph{Finding global maximum}: Although finding local maximum is
  relatively easy with developed algorithms, it is generally hard to
  guarantee global maximum in a problem where the objective function is
  complex or the number of decision variables is large. Also, there are
  discussions on how to avoid getting trapped in a local optimal in the
  literature.
\item
  \emph{optimising non-smooth function}: When the objective function is
  non-differentiable, derivative information can not be obtained, which
  means traditional gradient- or Hessian- based methods are not
  feasible. Stochastic optimisation method could be an alternative to
  solve these problems.
\item
  \emph{computation speed}: The optimisation procedure needs to be fast
  to compute since tours produces real-time animation of the projected
  data.
\item
  \emph{consistency result in stochastic optimisation}: In stochastic
  algorithm, researchers usually set a seed to ensure the algorithm
  producing the same result for every run. This practice supports
  reproducibility, while less efforts has been made to guarantee
  different seeds will provide the same result.
\item
  \emph{high-dimensional decision variable}: In projection pursuit, the
  decision variable includes all the entries in the projection matrix,
  which is high-dimensional. Researcher would be better off if they can
  understand the relative position of different projection matrix in the
  high-dimensional space.
\item
  \emph{role of interpolation in PP optimisation}: An optimisation
  procedure usually involves iteratively finding projection bases that
  maximises the index function, while tour requires geodesic
  interpolation between these bases to produce a continuous view for the
  users. It would be interesting to see if the interpolated bases could,
  in reverse, help the optimisation reach faster convergence.
\end{itemize}

\emph{Think about how does your package help people to understand
optimisation}

\begin{itemize}
\tightlist
\item
  diagnostic on stochastic optim
\item
  vis the progression of multi-parameter decision variable
\item
  understanding learning rate - neighbourhood parameter
\item
  understand where the local \& global maximum is found - trace plot -
  see if noisy function
\end{itemize}

\hypertarget{visual-diagnostic-system}{%
\section{Visual diagnostic system}\label{visual-diagnostic-system}}

\hypertarget{visual-diagnostics}{%
\subsection{Visual diagnostics}\label{visual-diagnostics}}

Random search methods has a black-box machinism and focuses solely on
finding the global maximum point, while the projection pursuit problem
we have is aiming at \emph{exploring} the data and thus is interested in
how the algorithm finds its maximum. This motivates us \textbf{to
develop a visual diagnostic system for exploring the optimisation
searching path}.

The necessity of developing such a system rather than simply producing
different diagnostic plots is because there is always needs to develop a
function specific for diagnosing one particular variables and these
functions developed are not reusable at all. Thus we want to establish a
set of rules that prescribe the diagnostic of iterative algorithms
systematically.

The idea of unifying all the diagnostic plots under one framework is
inspired by the concept of \emph{gramma of
graphic}\citep{wickham2010layered}, which powers the primary graphical
system in R, ggplot2 \citep{ggplot2}. In gramma of graphic, plots are
not defined by its appearance (i.e.~boxplot, histogram, scatter plot
etc) but by ``stacked layers''. By this design, ggplot doesn't need to
develop a gazillion of functions that each produces a different type of
plot, instead, it defines layers and allow users to specify the plot
through these defined layers.

{[}Do I need this paragraph to details the gramma of graphic? xxx{]}

\hypertarget{glocal-object}{%
\subsection{Glocal object}\label{glocal-object}}

Ggplot prescribes how to make a graphic but it doesn't prescribe how to
run a diagnostic. {[}need to have a paragraph or two here to describe
how I come up with the design of four components in the global object -
need to related to the component in optimisation. xxx{]}.

A global object used for diagnosing an optimisation is defined with four
components: decision variable, value of objective function, iterators
and other parameter of interest. In the projection pursuit guided tour,
the decision variable is the projection matrix, the value of objective
function is index value. There are three iterators: \texttt{id} is the
smallest ordering unit that increases by one for each observatoin;
\texttt{tries} is a larger order unit, which is updated once a
search-and-interpolate step is finished. A third iterator \texttt{loop}
is used to record the number of repitition in the search step and starts
over from one at the beginning of a new \texttt{tries}. Since there are
different methods used in the projection pursuit guided tour, we are
interested to compare between different methods, thus \texttt{method} is
created as another parameter of interest. The neighbourhood parameter
alpha is always interested in the direct search methods since it
controls the size of the sampling space, thus \texttt{alpha} is another
parameter of interest. \texttt{info} is created to label different stage
in the searching process and it is the third parameter of interest. A
sketch of the global object for projection pursuit guided tour is
presented in Figure \ref{fig:glb-obj}.

\begin{figure}
\includegraphics[width=1\linewidth,height=0.2\textheight]{/Users/hzha400/Documents/3.PhD/paper-tour-vis/figures/global_obj} \caption{\label{glb-obj}The global object in projection pursuit guided tour.}\label{fig:glb-obj}
\end{figure}

\hypertarget{diagnostics-plots}{%
\section{Diagnostics plots}\label{diagnostics-plots}}

\hypertarget{simulated-data}{%
\subsection{Simulated data}\label{simulated-data}}

Two set of simulated data are used in the demo of the visual diagnostics
in projection pursuit guided tour. A small dataset consists of 1000
randomly simulated observations of five variables (\texttt{x1},
\texttt{x2}, \texttt{x8}, \texttt{x9}, \texttt{x10}). \texttt{x2} is the
informative variable simulated from two bi-modal normal distribution
centred at -3 and 3 with variance of one and the other four are
simulated from non-informative standard random normal distributions. The
data has been scaled to ensure \texttt{x2} has variance of 1. The goal
is to find the 1D projection of bi-modal shape, which correspondes to
the projection matrix (vector) of \texttt{{[}0,\ 1,\ 0,\ 0,\ 0{]}}.

A larger dataset contains more informative variables (\texttt{x3} to
\texttt{x7}) of different types. The distribution of all the variables
except \texttt{x3} is plotted below and \texttt{x3} takes 500 positive
one and 500 negative one. {[}should I introduce the dist for each var?
xxx{]} {[}also feel like we don't really use \texttt{x3} to \texttt{x6},
should we not mention about these? xxx{]}

\includegraphics{paper_files/figure-latex/origin-data-1.pdf}

Once the dataset is sent to the tourr package, all the information
generated will be stored in a global structure. The global structure
consists of six columns: \texttt{basis}, \texttt{index\_val},
\texttt{tries}, \texttt{info}, \texttt{loop}, \texttt{id} and captured
all the basis generated during whole tour process. The example below
presents the global object of a 1D projection of the small dataset with
geodesic searching method.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{holes_1d_geo }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 8
##   basis           index_val tries info            loop method        alpha    id
##   <list>              <dbl> <dbl> <chr>          <dbl> <chr>         <dbl> <int>
## 1 <dbl[,1] [5 x ~     0.749     1 start             NA <NA>            0.5     1
## 2 <dbl[,1] [5 x ~     0.749     1 direction_sea~     1 search_geode~  NA       2
## 3 <dbl[,1] [5 x ~     0.749     1 direction_sea~     1 search_geode~  NA       3
## 4 <dbl[,1] [5 x ~     0.749     1 direction_sea~     1 search_geode~  NA       4
## 5 <dbl[,1] [5 x ~     0.749     1 direction_sea~     1 search_geode~  NA       5
\end{verbatim}

\texttt{tries} has an increment of one once the generator is called
(equivalently a new target basis is generated); \texttt{info} records
the stage the basis is in. This would include the \texttt{interpolation}
stage and the detailed stage in the optimisation i.e.
\texttt{direction\_search}, \texttt{best\_direction\_search},
\texttt{line\_search}and \texttt{best\_line\_search} for geodesic
searching (\texttt{search\_geodesic}); \texttt{random\_search} and
\texttt{new\_basis} for simulating annealing (\texttt{search\_better}).
\texttt{loop} is the counter used for the optimisation procedure and
thus will be \texttt{NA} for interpolation steps. \texttt{id} creates a
sequential order of the basis. This information will be stored and
printed when the optimisation ends and can be turned off via
\texttt{print\ =\ FALSE}. Additional messages during the optimisation
can be displayed via \texttt{verbose\ =\ TRUE}. Another examples is a 2D
projection of the larger dataset with two informative variable
(\texttt{x2} and \texttt{x7}) using search\_better method. Notice in
this example, the dimension of the bases becomes 6 by 2.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{holes_2d_better }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{(}\DecValTok{5}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 8
##   basis             index_val tries info           loop method       alpha    id
##   <list>                <dbl> <dbl> <chr>         <dbl> <chr>        <dbl> <int>
## 1 <dbl[,2] [6 x 2]>     0.804     1 start            NA <NA>           0.5     1
## 2 <dbl[,2] [6 x 2]>     0.793     1 random_search     1 search_bett~   0.5     2
## 3 <dbl[,2] [6 x 2]>     0.784     1 random_search     2 search_bett~   0.5     3
## 4 <dbl[,2] [6 x 2]>     0.773     1 random_search     3 search_bett~   0.5     4
## 5 <dbl[,2] [6 x 2]>     0.795     1 random_search     4 search_bett~   0.5     5
\end{verbatim}

\hypertarget{explore-scalar-parameters}{%
\subsection{Explore scalar parameters}\label{explore-scalar-parameters}}

The most interesting parameter to explore is the value of objective
function. The points recorded in the global object can be divided into
two broad categories: searching points and interpolating points

\begin{itemize}
\item
  \emph{Searching points} include the observations that are recorded in
  the searching algorithm in order to find the target basis. The points
  for target bases is also included in the searching points and there is
  one such point per \texttt{tries}.
\item
  \emph{interpolating points} exist in the guided tour to produce
  continuous animated view from one target basis to another and it
  doesn't have \texttt{loop} value.
\end{itemize}

\hypertarget{explore-searching-points}{%
\subsubsection{Explore searching
points}\label{explore-searching-points}}

As mentioned previously, the largest difficulties of exploring searching
points is its unknown number of observations per \texttt{tries}. Mapping
\texttt{id} on the x-axis will leave the \texttt{tries} with few
observations a small space in the plot, while those \texttt{tries} with
large number of search points towards the end occupying the vast
majority of the space in the plot.

This motivates the use of summarised statistics. At each iteration,
rather than knowing the index value of \emph{every} points, we are more
interested to know a general summary of all the points and more
importantly, the point with the largest \texttt{index\_val} since it
prescribes the geodesic interpolation and future searches.

Boxplot is a suitable candidate that provides five points summary of the
data, while it has one drawback: it doesn't report the number of point
in each box. We may risk losing information on how long it takes for the
search to find the target basis by displaying the boxplot alone for all
\texttt{tries}. Thus, the number of point for each \texttt{tries} is
displayed at the bottom of each box and we provide options to switch
\texttt{tries} with small number of points to a point geometry. This is
achieved via the \texttt{cutoff} argument. A line geometry is also added
to link the points with the largest index value for each \texttt{tries}.
This helps to visualise the improvement made by each \texttt{tries}.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/points-tries-1.pdf}
\caption{\label{points}A comparison of plotting the same search points
with different plot designs. The left plot doesn't efficiently use the
plot space to convey information from the plot while the right plot
provides good summarisation of data and number of points in each tries.}
\end{figure}

\emph{Example: exploring searching points} The data is sourced from a 2D
projection of the larger dataset and \texttt{search\_better} is used
with \texttt{max.tries\ =\ 500}. In Figure \ref{fig:points-id} and
\ref{fig:points}, a comparison has been made on visualising the
searching points with \texttt{id} and \texttt{tries} on the x-axis,
colored by \texttt{tries}. In Figure \ref{fig:points-id}, the searching
points of the first few \texttt{tries} are squeezed in a small width
leaving the large uninteresting searching points in the last three
\texttt{tries} taking a vast majority of the plotting space. While in
Figure \ref{fig:points} the data is spaced by \texttt{tries} evenly in
the plot. Label at the bottom indicates the number of observations in
each tries and facilitates the choice of cutoff to switch from point
geometry to boxplot geometry (\texttt{cutoff\ =\ 15}). The line geometry
suggest the largest improvement happens at \texttt{tries\ =\ 5}.

\hypertarget{explore-interpolating-points}{%
\subsubsection{Explore interpolating
points}\label{explore-interpolating-points}}

Plotting the interpolating points as time series data allows us to
diagnose characteristics of different configurations and index
functions. Here we present two examples of using plots to diagnose the
tour algorithm and different index functions.

\emph{Example: Interruption} This examples uses \texttt{search\_better}
for a 2D projection on the larger dataset using the \texttt{holes}
index. As mentioned previously, the interpolation starts from the
current basis to the target basis, which has been found by the
projection pursuit algorithm to have a higher index value. After the
interpolation, the target basis will become the current basis and send
back to the projection pursuit algorithm to find the next target basis.
From figure \ref{fig:interruption}, it is possible that there are bases
with index value higher than the target basis on the interpolation path
and these bases could be used to search for new basis in the next
iteration.

Thus an interruption is constructed to accept the interpolating bases up
to the one with the larger index value on the interpolation path, and
that basis is taken as the current basis for the next iteration. After
implementing this interruption, the tracing plot with the same
configuration is shown on the lower panel. We can observe that rather
than interpolating to the target basis at \texttt{id\ =\ 62}, the
interpolation stops before the index value starts to decrease at
\texttt{id\ =\ 60}. This implementation results in a higher index value
in the end with fewer steps.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/interruption-1.pdf}
\caption{\label{interruption}Trace plots of the interpolated basis with
and without the interruption. The interruption stops the interpolation
when the index value starts to decrease at id = 60. The implementation
of the interuption finds an ending basis with higher index value using
fewer steps.}
\end{figure}

\emph{Example: Noisy index function} The interpolation path of holes
index, as seen in Figure \ref{fig:interruption}, is smooth, while this
may not be the case for more complicated index function.
\texttt{kol\_cdf} index, an index function based on Kolmogorov test,
compares the difference between a projection matrix and a randomly
generated normal distribution based on cumulated distribution function
(CDF). Several visualisations below shows some characteristic of this
index function.

Figure \ref{fig:geodesic-better} compares the tracing plot of the
interpolating points for \texttt{search\_geodesic} and
\texttt{search\_better}. Rather than a smooth interpolation, the
interpolation path for \texttt{kol\_cdf} shows a zig-zag pattern.
Polishing step has done much more work to reach the final index value
for \texttt{search\_geodesic} than \texttt{search\_better} and this
indicates that noisy index's favour of a random search method than
ascent method.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/geodesic-better-1.pdf}
\caption{Comparison of two different searching methods: search\_geodesic
and search\_better on 1D projection problem for a noisy index: kol\_cdf.
The geodesic search rely heavily on the polishing step to find the final
index value while search better works well.}
\end{figure}

Moving from a 1D projection on a dataset with only one informative
variable, we now introduce another informative variable in the data and
remain 1D projection. In this problem, there are two local maximum being
0.17 when the projection matrix is \([0, 1, 0, 0, 0, 0]\) and 0.228 when
the projection matrix is \([0, 0, 1 ,0, 0, 0]\). As in Figure
\ref{fig:1d-2var-different-seeds}, using \texttt{search\_better} with
different seeds, both local maximum can be found. A simulated annealing
algorithm, \texttt{search\_better\_random} in Figure
\ref{fig:1d-2var-better-random}, can always find the global maximum at a
cost of a large number of \texttt{tries}.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/1d-2var-different-seeds-1.pdf}
\caption{The trace plot search better in a 1D projection problem with
two informative variables using different seeds (without polishing).
Since there are two informative variables, setting different value for
seed will lead search better to find either of the local maximum.}
\end{figure}

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/1d-2var-better-random-1.pdf}
\caption{Using search better random for the problem above will result in
finding the global maximum but much larger number of iteration is
needed.}
\end{figure}

\hypertarget{adding-more-variables-to-the-mapping}{%
\subsubsection{Adding more variables to the
mapping}\label{adding-more-variables-to-the-mapping}}

At previous two sections, only the iterator and the index value are
mapped onto the x and y aesthetics of the plot; while more aesthetics
i.e.~color, could be added to compare other parameters in the global
object. Two examples are shown below to explore and compare different
searching methods and neighbourhood parameter alpha.

\emph{Example: Polish} In principle, all the optimisation routines
should result in the same output on the same problem while this may not
be the case in real application. This motivates the creation of a
polishing search that polishes the ending basis and achieves unity on
different methods.

\texttt{search\_polish} takes the ending basis of a given search as the
current basis and uses a brutal-force approach to sample a large number
of basis (\texttt{n\_sample}) in the neighbourhood, whose radius is
controlled by \texttt{polish\_alpha}. Among the \texttt{n\_sample}
basis, the one with the largest index value becomes the candidate. If
its index value of the candidate basis is larger than that of the
current basis, it becomes the current basis in the next iteration. If no
basis is found to have larger index value than the current basis, the
searching neighbourhood will be shrunk and the search continues. The
polishing search ends when one of the four stopping criteria is
satisfied:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  the two basis can't be too close
\item
  the percentage improvement of the index function can't be too small
\item
  the searching neighbourhood can't be too small
\item
  the number of iteration can't exceed the \texttt{max.tries}
\end{enumerate}

The usage of search\_polish is as follows. After the first tour, the
final basis from the interpolation is extracted and supplied into a new
tour with the \texttt{start} argument and \texttt{search\_polish} as the
searching function in the guided\_tour. All the other arguments should
remain the same.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123456}\NormalTok{)}
\NormalTok{holes_2d_geo <-}\StringTok{ }\KeywordTok{animate_xy}\NormalTok{(data_mult[,}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{, }\DecValTok{7}\OperatorTok{:}\DecValTok{10}\NormalTok{)],}\DataTypeTok{tour_path =} 
                             \KeywordTok{guided_tour}\NormalTok{(}\KeywordTok{holes}\NormalTok{(), }\DataTypeTok{d =} \DecValTok{2}\NormalTok{, }
                                         \DataTypeTok{search_f =}\NormalTok{ tourr}\OperatorTok{:::}\NormalTok{search_geodesic),}
                           \DataTypeTok{rescale =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{verbose =} \OtherTok{TRUE}\NormalTok{)}

\NormalTok{last_basis <-}\StringTok{ }\NormalTok{holes_2d_geo }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(info }\OperatorTok{==}\StringTok{ "interpolation"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{tail}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{pull}\NormalTok{(basis) }\OperatorTok{%>%}\StringTok{ }\NormalTok{.[[}\DecValTok{1}\NormalTok{]]}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123456}\NormalTok{)}
\NormalTok{holes_2d_geo_polish <-}\StringTok{ }\KeywordTok{animate_xy}\NormalTok{(data_mult[,}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{, }\DecValTok{7}\OperatorTok{:}\DecValTok{10}\NormalTok{)], }\DataTypeTok{tour_path =} 
                                    \KeywordTok{guided_tour}\NormalTok{(}\KeywordTok{holes}\NormalTok{(), }\DataTypeTok{d =} \DecValTok{2}\NormalTok{, }
                                                \DataTypeTok{search_f =}\NormalTok{ tourr}\OperatorTok{:::}\NormalTok{search_polish),}
                                  \DataTypeTok{rescale =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{verbose =} \OtherTok{TRUE}\NormalTok{, }
                                  \DataTypeTok{start =}\NormalTok{ last_basis)}
\end{Highlighting}
\end{Shaded}

The following example conducted a 2D projection on the larger dataset
using search better with different configurations. \texttt{max.tries} is
a hyperparameter that controls the maximum number of try without
improvement and its default value is 25. As shown in Figure
\ref{fig:trace-compare}, after polishing, both trials attain the same
index value. However, a small \texttt{max.tries} of 25 is not sufficient
for the algorithm to find the true maximum. This is because 25 tries is
not sufficient for the 2D searching space.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/polish-1.pdf}
\caption{\label{trace-compare}Breakdown of index value when using
different max.tries in search better in conjunction with search polish.
Both attain the same final index value after the polishing while using a
max.tries 25 is not sufficient to find the ture maximum.}
\end{figure}

\emph{Example: The neighbourhood parameter alpha} Add an example on
comparing the neighbourhood parameter in search\_better \&
search\_posse.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# nrow(holes_2d_better_max_tries)}
\CommentTok{# nrow(holes_2d_pos)}
\end{Highlighting}
\end{Shaded}

\hypertarget{explore-matrix-parameter}{%
\subsection{Explore matrix parameter}\label{explore-matrix-parameter}}

Sometimes, a parameter to explore could be a vector or matrix instead of
scalar, for example, in tour, we are interested to explore the
projection basis in the vector space. This imposes difficulties in
visualisation since we are bounded to perceive at most three dimensions.
Thus, principal component analysis is used to reduce the dimension of
projection bases and the first two principal components are mapped to
the x and y axis of the plot. Additional variable of interest could be
mapped to the color aesthetics to for exploration.

\emph{Example: understand search\_geodesic via mapping \texttt{info} to
color} \texttt{search\_geodesic} is a two-stage ascending algorithm with
four different stages in the search and a PCA plot useful to understand
how the algorithm works. Starting from the start basis, a directional
search is conducted in a narrow neighbourhood on five random directions.
The best one is picked and a line search is then run on the geodesic
direction to find the target basis. The starting and target basis are
then interpolated. In the next iteration, the target basis becomes the
current basis and then procedures continues. {[}should probably reword
this part with info levels xxx{]}

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/pca-1.pdf}
\caption{\label{pca}PCA plot of search geodesic Coloring by info allows
for better understanding of each stage in the geodesic search}
\end{figure}

\emph{Example: initial value for polishing alpha in search geodesic}
\texttt{search\_polish} is a brutal-force algorithm that evaluate 1000
points in the neighbourhood at each loop. Setting an appropriate initial
value for polish\_alpha would avoid wasting search on large vector space
that are not likely to produce higher index value. A default initial
value for polishing step is 0.5 and we are interested in whether this is
an appropriate initial value. The problem is a 1D projection of the
small dataset using \texttt{search\_geodesic} and followed by
\texttt{search\_polish}. Figure \ref{fig:polish-alpha} display all
projection bases on the first two principal components, colored by the
\texttt{polish\_alpha} parameter in the polishing step. Rather than
concentrating on the ending basis from \texttt{search\_geodesic} as what
polishing step is designed, it searches a much larger vector space that
are unnecessary. Thus a user-supplied smaller initial value for
\texttt{polish\_alpha} would be ideal.

On the right panel of Figure \ref{fig:polish-alpha-tracing}, the
\texttt{polish\_alpha} is initialised as the projection distance between
the last two target bases and we observe a concentrated searching space
near the ending basis. With the supplied initial value for
\texttt{polish\_alpha}, the algorithm reaches the same ending index
value with fewer iterations.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/polish-alpha-1.pdf}
\caption{PCA plot of two different polish alpha initialisations. A
default polish alpha = 0.5 searches a larger space that is unncessary
while a small customised initial value of polish alpha will search near
the ending basis.}
\end{figure}

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/polish-alpha-tracing-1.pdf}
\caption{Comparing the trace of two different polish alpha
initialisations. Both intialisations reach the same ending index values}
\end{figure}

\hypertarget{real-time-animated-diagnostic-plots}{%
\section{Real-time animated diagnostic
plots}\label{real-time-animated-diagnostic-plots}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{holes_1d_geo }\OperatorTok{%>%}\StringTok{ }\KeywordTok{explore_proj_pca}\NormalTok{(}\DataTypeTok{animate =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{col =}\NormalTok{ info) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"bottom"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{vis-package}{%
\section{Vis package}\label{vis-package}}

Everything is coded up in a package.

\clearpage

\bibliographystyle{agsm}
\bibliography{biblio.bib}

\end{document}
