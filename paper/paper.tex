% !TeX program = pdfLaTeX
\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage{textcomp}
\usepackage[hyphens]{url} % not crucial - just used below for the URL
\usepackage{hyperref}
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%

%% load any required packages here


\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}



\begin{document}


\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if0\blind
{
  \title{\bf Title here}

  \author{
        Author 1 \thanks{The authors gratefully acknowledge \ldots{}} \\
    Department of YYY, University of XXX\\
     and \\     Author 2 \\
    Department of ZZZ, University of WWW\\
      }
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Title here}
  \end{center}
  \medskip
} \fi

\bigskip
\begin{abstract}
Friedman \& Tukey commented on their intial paper on projection pursuit
in 1974 that ``the technique use for maximising the projection index
strongly influences both the statistical and the computational aspects
of the procedure.'' While many projection pursuit indices have been
proposed in the literature, few concerns the optimisation procedure. In
this paper, we developed a system of diagnostics aiming to visually
learn how the optimisation procedures find its way towards the optimum.
This diagnostic system can be applied to more general to help
practitioner to unveil the black-box in randomised iteartive
(optimisation) algorithms. An R package, ferrn, has been created to
implement this diagnostic system.
\end{abstract}

\noindent%
{\it Keywords:} optimisation, projection pursuit, guided tourr, visual, diagnostics, R
\vfill

\newpage
\spacingset{1.45} % DON'T change the spacing!

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

In an optimization problem the goal is to find the best solution within
the space of all feasible solutions which typically is represented by a
set of constraints. The problem consists on optimizing an objective
function \(f: S \rightarrow \Re\) with \(S \in \Re^n\) in a reduced
spaced given by the problem constraints to either minimize or maximize a
function\ldots{}. Gradient based optimization has been typically used to
solve such problems. However, there are many situations where
derivatives of an objective function are unavailable or unreliable and
therefore traditional methods based on derivatives are not the best
option to solve an optimization problem.

Derivative free methods provides another option to optimise the
objective function without evaluating any gradient or Hessian
information and a particular class of methods: direct search, has gained
its popularity through its conceptual simplicity. However, the whole
searching process in the algorithm remains a black-box. Plots are
usually used to evaluate and compare the performance of different
algorithms but it can easily become tedious because the code will have
to be modified significantly when comparing different parameters in the
algorithms. For example, a categorical variable with 5 levels can be
easily mapped onto color while mapping another categorical variable with
30 levels will not make the plot informative. Thus the plot needs to be
re-designed to better suits the characteristics of the parameter
(whether the parameter is a scalar or a matrix? whether the parameter is
quantitative or categorical? If categorical, how many levels does the
parameter have?). This motivates the design of a visual diagnostic
framework for optimisation algorithms based on the idea of a
\emph{global object}.

The paper is organised as follows. Section \ref{DFO} gives a general
literature review of optimisation, specifically derivative free
optimisation. Section \ref{vis-diag} presents the new idea of
constructing a systematic visual framework that diagnoses the components
of an optimisation procedure (parameters, searching path, etc). The rest
of the paper serves as a comprehensive example of using the visual
diagnostics on one particular problem: \emph{projection pursuit guided
tour}. Some background knowledge of projection pursuit guided tour is
provided in Section \ref{tour}. Section \ref{apply} applies the concepts
proposed in section \ref{vis-diag} in the tour problem and sets up the
data. The last section, Section \ref{plots}, presents the visual
diagnostic plots and explains how they can help to understand different
aspects of the optimisation in tour.

\hypertarget{DFO}{%
\section{Derivative free optimisation}\label{DFO}}

Given an objective function \(f\), one way of optimising it is to equate
its gradient to zero. In modern optimisation problems, gradient
information can be hard to evaluate or sometimes even impossible and
Derivative-Free Optimisation (DFO) methods can be useful to approach
these problems. One common class of methods in DFO is
\emph{Direct-search methods}. Coined by \citet{hooke1961direct}, direct
search methods don't require any gradient or Hessian information and has
gained its popularity through its simplicity in use and reliability in
solving complicated practical problems. Depends on whether a random
sample is used in the search, this class of methods can be further
classified as \emph{stochastic} or \emph{deterministic}. The stochastic
version of the direct-search methods will be the main optimisation
procedure analysed in this paper.

{[}How about adding more details into derivative free methods? ppp{]}

\hypertarget{difficulties}{%
\subsection{Difficulties}\label{difficulties}}

{[}Are we using projection pursuit/guided tour to better understand the
convergence of optimization algorithms visually in combination with the
algorithms discussed below? Or we are focusing on the optimisation
problem only within the project pursuit context? Some of the problems
listed below are also applicable to optimization problem in general too.
ppp{]}

Below listed several issues in projection pursuit optimisation. Some are
general optimisation problems, while others are more specific for PP
optimisation.

\begin{itemize}
\item
  \emph{Finding global maximum}: Although finding local maximum is
  relatively easy with developed algorithms, it is generally hard to
  guarantee global maximum in a problem where the objective function is
  complex or the number of decision variables is large. Also, there are
  discussions on how to avoid getting trapped in a local optimal in the
  literature.
\item
  \emph{optimising non-smooth function}: When the objective function is
  non-differentiable, derivative information can not be obtained, which
  means traditional gradient- or Hessian- based methods are not
  feasible. Stochastic optimisation method could be an alternative to
  solve these problems.
\item
  \emph{computation speed}: The optimisation procedure needs to be fast
  to compute since tours produces real-time animation of the projected
  data.
\item
  \emph{consistency result in stochastic optimisation}: In stochastic
  algorithm, researchers usually set a seed to ensure the algorithm
  producing the same result for every run. This practice supports
  reproducibility, while less efforts has been made to guarantee
  different seeds will provide the same result.
\item
  \emph{high-dimensional decision variable}: In projection pursuit, the
  decision variable includes all the entries in the projection matrix,
  which is high-dimensional. Researcher would be better off if they can
  understand the relative position of different projection matrix in the
  high-dimensional space.
\item
  \emph{role of interpolation in PP optimisation}: An optimisation
  procedure usually involves iteratively finding projection bases that
  maximises the index function, while tour requires geodesic
  interpolation between these bases to produce a continuous view for the
  users. It would be interesting to see if the interpolated bases could,
  in reverse, help the optimisation reach faster convergence.
\end{itemize}

\emph{Think about how does your package help people to understand
optimisation}

\begin{itemize}
\tightlist
\item
  diagnostic on stochastic optim
\item
  vis the progression of multi-parameter decision variable
\item
  understanding learning rate - neighbourhood parameter
\item
  understand where the local \& global maximum is found - trace plot -
  see if noisy function
\end{itemize}

\hypertarget{vis-diag}{%
\section{Visual diagnostic system}\label{vis-diag}}

{[}I would expand this section more as the core contribution. ppp{]}

\hypertarget{origin-idea}{%
\subsection{Origin idea}\label{origin-idea}}

Random search methods has a black-box mechanism and focuses solely on
finding the global maximum point, while the projection pursuit problem
we have aims at \emph{exploring} the data and thus is interested in how
the algorithm finds its maximum. This motivates us \textbf{to develop a
visual diagnostic system for exploring the optimisation searching path}.

The necessity of developing such a system rather than simply producing
different diagnostic plots is because the diagnostics of each variable
requires a different function and these functions can't be scaled to
other problems. Thus we want to establish a set of rules that can
generalise the diagnostic of iterative algorithms.

The idea of generalising all the diagnostic plots under one framework is
inspired by the concept of \emph{grammar of
graphic}\citep{wickham2010layered}, which powers the primary graphical
system in R, ggplot2 \citep{ggplot2}. In grammar of graphic, plots are
not defined by its appearance (i.e.~boxplot, histogram, scatter plot
etc) but by ``stacked layers''. By this design, ggplot doesn't need to
develop a gazillion of functions that each produces a different type of
plot. Instead, it aesthetically maps the variables to the geometric
objects and builds the plot through different layers.

\hypertarget{global-object}{%
\subsection{Global object}\label{global-object}}

Ggplot requires a data frame that contains all the variables to plot and
a \emph{global object} is constructed as the data frame supplied to the
visual diagnostic plots to better suit the characters of iterative
optimisation algorithms. Given an optimisation algorithm, two primary
variables of interest are the \emph{decision variable} and the
\emph{value of the objective function}. \emph{iterators} indexes the
data collected and this order has time series feature that prescribes
the progression of the optimisation. Given the complexity of the
algorithm, there could be multiple iterators. There are other parameters
that can't be classified as one of the three categories but are also of
our interest. They are defined under the fourth category: \emph{other
parameter of interest}. This could include variables that are specific
for one particular algorithm. Below we show an example of defining the
global object of projection pursuit guided tour.

An optimisation procedure can easily generate hundreds or thousands
sampling points and the question becomes what are the points we want to
explore\ldots{} {[}the classification of searching or updating points
goes here and people should be clear what part of the points goes to the
plot - this is the data part not the plot part. {]}

In tour, all the points recorded in the global object can be divided
into two broad categories: searching points and interpolating points

\begin{itemize}
\item
  \emph{Searching points} include the observations recorded in the
  searching algorithm to find the target basis. The points for target
  bases is also included in the searching points and there is one such
  point per \texttt{tries}.
\item
  \emph{interpolating points} exist in the guided tour to produce
  continuous animated view from one target basis to another and it
  doesn't have \texttt{loop} value.
\end{itemize}

\hypertarget{visual-diagnostics}{%
\subsection{Visual diagnostics}\label{visual-diagnostics}}

Follow the research question we raised earlier, the purpose of visual
diagnostics is to understand

\begin{itemize}
\item
  Whether the procedure has provided an optimum and how the value of the
  objective function changes through the optimisation.
\item
  How does the searching space look like, that is, geometrically, where
  are the points located in the space.
\end{itemize}

Overall, the first question can be answered using a static plot with
x-axis showing the progression of the optimisation and y-axis showing
the value of the objective function. The second question can be
addressed via visualising the rotating high dimensional space. This
seems to be a hard task to see beyond 3D, but the fact is that we never
really see all the six faces of a cube at one time. The way humans
understand the dimension of a 3D object is either through rotating the
physical 3D object or using shade and line type to annotate the 3D
object in a paper or electronically. Thus we can do a similar rotation
on the screen to precieve even higher dimension. {[}there is likely to
be a learning curve - remember when learning geometry in school, it
takes a while to get used to see 3D cube on a paper{]}. Thus animated
visualisation is needed to preceive the optimisation path in the
searching space.

The plot design of visual diagnostics depends on the characteristics of
the variables to plot. If the searching points are of interest {[}point
geom is not good; need summarise. While updating points are more
manageable -\textgreater{} point geom{]}. However, one must realise that
with hundreds or thousands of searching points, exploring the sample
space in animation could be slow and this is because of the time it
takes to render hundreds point. {[}stratefy may help? - may need more
work here.{]}

Exploring the value of an objective function is cna be a simple task.
Because the iterator has a time series ordering feature, it goes onto
the x-axis as convention. The value of hte objective function goes to
the y-axis. Other parameter of interest can be represented using color
to present more information. {[}This is the case for our purpose with
method, but when the level goes higher or the parameter is quantitative,
color may not be a good option. {]}

An option to explore of the searching space is to explore a reduced
projection 2D space via principle component analysis or other
dimensional reduction methods. In this way, the first two principle
components will take up the x and y axis and all the other information
will be mapped using other aesthetic attribution. {[}need to think
further about how different type of variables can be shown{]}. While
explore the reduced space is an initial attempt to understand the
searching space, there are existing technology for rotating a higher
dimensional space for visualisation. Geozoo is an option. It generates
random points on the high dimensional space and we can overlay it with
the points on the optimisation path to visualise the spread of it on the
high-D sphere.

\hypertarget{tour}{%
\section{Projection pursuit guided tour}\label{tour}}

From Section \ref{tour}, we presents a comprehensive case study on how
to use the visual diagnostics to explore the optimisation in a specific
problem: projection pursuit guided tour. Section \ref{tour} aims to
provide non-experts with an overview of the problem content and the
existing optimisation procedures used in projection pursuit guided tour.
For those who are already familiar with the technique, this section can
be skipped.

The optimisation problem we're interested in is in the context of
projection pursuit. Coined by \citet{friedman1974projection}, projection
pursuit is a method that detects the interesting structure
(i.e.~clustering, outliers and skewness) of multivariate data via
projecting it in lower dimensions. A Projection Pursuit Index (PPI) is a
function of the projection matrix (a.k.a projection angle, projection
basis) measuring the ``interestingness'' of data and we refer the value
of PPI function as \emph{index value}. In the literature, the indices
being proposed include Legendre index \citep{friedman1974projection},
hermite index \citep{hall1989polynomial}, natural hermite index
\citep{cook1993projection}, chi-square index
\citep{posse1995projection}, LDA index \citep{lee2005projection} and PDA
index \citep{lee2010projection}. {[}Any literature on holes index?
xxx{]}

As \citet{friedman1974projection} noted ``\ldots{}, the technique use
for maximising the projection index strongly influences both the
statistical and the computational aspects of the procedure.'' A suitable
optimisation procedure is needed to find the projection angle that
maximises the PPI and the quality of the optimisation largely affect the
interesting projections one could possibly observe.

Projection pursuit is usually used in conjunction with a tour method
called \emph{guided tour}. Tour explores the multivariate data
\emph{interactively} via playing a series of projections, that form a
\emph{tour path}, like movie frames in real time. Starting from a
randomly generated projection basis, projection pursuit searches for a
target basis with higher index value and guided tour interpolates
geodesically between the initial basis and the target basis. This series
of bases forms a tour path and the projection of the data on these bases
is played in real time. This search-and-interpolate process is repeated
until no basis can be found with higher index value. Modified from
\citet{buja2005computational}, Figure \ref{tour-path} vividly depicts
the tour path in guided tour. Guided tour, along with other types of
tour, has been implemented in the \emph{tourr} package in R, available
on the Comprehensive R Archive Network at
\url{https://cran.r-project.org/web/packages/tourr/}
\citep{wickham2011tourrpackage}.

\begin{figure}
\includegraphics[width=1\linewidth,height=0.6\textheight]{/Users/hzha400/Documents/3.PhD/paper-tour-vis/figures/tour_path_increasing} \caption{\label{tour-path}An illustration of the tour path}\label{fig:tour-path}
\end{figure}

{[}doubt if I need the following. xxx - maybe an algorithmatic version
of guide tour would be helpful for non-expert to understand the
method?{]}

\hypertarget{optimisation-in-projection-pursuit}{%
\subsection{Optimisation in projection
pursuit}\label{optimisation-in-projection-pursuit}}

{[}thinking if the following three should be presented as algorithms or
plain description is fine. xxx{]}

There are three existing methods for optimisating PPI function and we
review them below. \citet{posse1995projection} used a stochastic direct
search method, a random search algorithm to sample new bases in the
neighbourhood of the current basis defined by the radius of the
p-dimensional sphere, \(c\). The new basis is taken as the target basis
if it has higher index value, or the sampling continues. If no basis is
found to have higher index value after a certain number of tries \(n\),
the radius \(c\) is halved. The algorithm stops when the maximum number
of iteration is attained or the radius \(c\) is less than a
pre-determined number.

\citet{cook1995grand} explained the use of a gradient ascent
optimisation with the assumption that the index function is continuous
and differentiable. Since some indices could be non-differentiable, the
computation of derivative is replaced by a pseudo-derivative of
evaluating five randomly generated directions in a tiny nearby
neighbourhood. Taking a step on the straight derivative direction has
been modified to maximise the projection pursuit index along the
geodesic direction.

Simulated annealing
\citep[\citet{kirkpatrick1983optimization}]{bertsimas1993simulated} is a
non-derivative procedure based on a non-increasing cooling scheme
\(T(i)\). Given an initial \(T_0\), the temperature at iteration \(i\)
is defined as \(T(i) = \frac{T_0}{log(i + 1)}\). The simulated annealing
algorithm works as follows. Given a neighbourhood parameter \(\alpha\)
and a randomly generated orthonormal basis \(B\), a candidate basis is
constructed as \(B_j = (1- \alpha)B_i + \alpha B\) where \(B_i\) is the
current basis. If the index value of the candidate basis is larger than
the one of the current basis, the candidate basis becomes the target
basis. If it is smaller, the candidate is accepted with probability
\(A = \min \left(\exp(-\frac{I(B_j) - I(B_i)}{T(i)}), 1 \right)\) where
\(I(.)\) is the index function.

Below listed several features characterise the optimisation procedures
needed in projection pursuit

\begin{itemize}
\item
  \emph{Being able to handle non-differentiable PPI function}: The PPI
  function could be non-differentiable, thus derivative free methods are
  preferred.
\item
  \emph{Being able to optimise with constraints}: The constraint comes
  from projection matrix being an orthonormal matrix.
\item
  \emph{Being able to find both local and global maximum}: Although the
  primary interest is to find the global maximum, local maximum could
  also reveal structures in the data that are of our interest.
\end{itemize}

\hypertarget{apply}{%
\section{Visual diagnostic in guided tour}\label{apply}}

In this section, we present the simulated data along with how the global
object can be applied in guided tour.

\hypertarget{global-object-1}{%
\subsection{Global object}\label{global-object-1}}

In the projection pursuit guided tour, the decision variable is the
projection matrix, the value of objective function is the index value.
There are three iterators: \texttt{id} is the smallest ordering unit
that increases by one for each observation; \texttt{tries} is updated
once a search-and-interpolate step is finished. A third iterator
\texttt{loop} is used to record the number of repetition in the search
step and starts over from one at the beginning of a new \texttt{tries}.
Three other parameters of our interest includes \texttt{method},
\texttt{alpha} and \texttt{info}. \texttt{method} identifies the name of
the searching method used and we are interested in comparing the
performance between different algorithms under direct search. The
neighbourhood parameter \texttt{alpha} controls the size of the sampling
space and we are interested to understand how the searching space
shrinks as the algorithm progresses. \texttt{info} labels different
stages in the searching process. A sketch of the global object for
projection pursuit guided tour is presented in Figure \ref{fig:glb-obj}.

\begin{figure}
\includegraphics[width=1\linewidth,height=0.2\textheight]{/Users/hzha400/Documents/3.PhD/paper-tour-vis/figures/global_obj} \caption{\label{glb-obj}The global object in projection pursuit guided tour.}\label{fig:glb-obj}
\end{figure}

\hypertarget{simulated-data}{%
\subsection{Simulated data}\label{simulated-data}}

{[}I would add the maths here to describe the simulations. ppp{]}

Two set of simulated data are used in the demo of the visual diagnostics
in projection pursuit guided tour. A small dataset consists of 1000
randomly simulated observations of five variables (\texttt{x1},
\texttt{x2}, \texttt{x8}, \texttt{x9}, \texttt{x10}). \texttt{x2} is the
informative variable simulated from two bi-modal normal distribution
centred at -3 and 3 with variance of one and the other four are
simulated from non-informative standard random normal distributions. The
data has been scaled to ensure \texttt{x2} has variance of 1. The goal
is to find the 1D projection of bi-modal shape, which corresponds to the
projection matrix (vector) of \texttt{{[}0,\ 1,\ 0,\ 0,\ 0{]}}.

A larger dataset contains more informative variables (\texttt{x3} to
\texttt{x7}) of different types. The distribution of all the variables
except \texttt{x3} is plotted in Figure \ref{origin-data} and
\texttt{x3} takes 500 positive one and 500 negative one. {[}should I
introduce the dist for each var? xxx{]} {[}also feel like we don't
really use \texttt{x3} to \texttt{x6}, should we not mention about
these? xxx{]}

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/origin-data-1.pdf}
\caption{\label{origin-data} The distribution of simulated data except
x3}
\end{figure}

In tour, when the optimisation ends the global object will be stored and
printed and can be turned off via \texttt{print\ =\ FALSE}. Additional
messages during the optimisation can be displayed via
\texttt{verbose\ =\ TRUE}. Below presented the global object of the 1D
projection using the small dataset. {[}the printing is not ideal as it
doesn't show all the columns. xxx{]}

\begin{verbatim}
## # A tibble: 5 x 8
##   basis           index_val tries info            loop method        alpha    id
##   <list>              <dbl> <dbl> <chr>          <dbl> <chr>         <dbl> <int>
## 1 <dbl[,1] [5 x ~     0.749     1 start             NA <NA>            0.5     1
## 2 <dbl[,1] [5 x ~     0.749     1 direction_sea~     1 search_geode~  NA       2
## 3 <dbl[,1] [5 x ~     0.749     1 direction_sea~     1 search_geode~  NA       3
## 4 <dbl[,1] [5 x ~     0.749     1 direction_sea~     1 search_geode~  NA       4
## 5 <dbl[,1] [5 x ~     0.749     1 direction_sea~     1 search_geode~  NA       5
\end{verbatim}

\hypertarget{plots}{%
\section{Diagnostics plots}\label{plots}}

Below we will present several examples to diagnose different aspect of
the tour optimisation. We will first provide examples on producing 1)
static plots to explore the value of objective function and 2) animated
plots to explore the searching space and then a more sophisticated
example that combines both to understand how to optimise a noisy and
complex index function. In both section, we will first provide a toy
example that is easy to grasp and one or two examples that help us
understand the optimisation algorithm and parameter choice better.

\hypertarget{static}{%
\subsection{Explore the value of objective function}\label{static}}

\hypertarget{toy-example-exploring-searching-points}{%
\subsubsection{Toy example: exploring searching
points}\label{toy-example-exploring-searching-points}}

The largest difficulties of exploring searching points is its unknown
number of observations per \texttt{tries}. Mapping \texttt{id} on the
x-axis will leave the \texttt{tries} with few observations a small space
in the plot, while those \texttt{tries} with large number of search
points (usually towards the end) occupy the vast majority of the plot
space. This motivates to summarise the points in each \texttt{tries}. At
each iteration, rather than knowing the index value of \emph{every}
points, we are more interested to know a general summary of all the
points and more importantly, the point with the largest
\texttt{index\_val} since it prescribes the geodesic interpolation and
future searches.

Boxplot is a suitable candidate that provides five points summary of the
data, however it has one drawback: it doesn't report the number of point
in each box. We may risk losing information on how many points it takes
to find the target basis by displaying the boxplot alone for all
\texttt{tries}. Thus, the number of point for each \texttt{tries} is
displayed at the bottom of each box and we provide options to switch
\texttt{tries} with small number of points to a point geometry, which is
achieved via the \texttt{cutoff} argument. A line geometry is also added
to link the points with the largest index value in each \texttt{tries}.
This helps to visualise the improvement made by each \texttt{tries}.

\emph{Example: exploring searching points} The larger dataset is used
for 2D projection with \texttt{search\_better} and
\texttt{max.tries\ =\ 500}. In Figure \ref{points}, the searching points
with \texttt{id} and \texttt{tries} on the x-axis, colored by
\texttt{tries}. Label at the bottom indicates the number of observations
in each tries and facilitates the choice of cutoff to switch from point
geometry to boxplot geometry (\texttt{cutoff\ =\ 15}). The line geometry
suggests the largest improvement happens at \texttt{tries\ =\ 5}.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/points-tries-1.pdf}
\caption{\label{points}A comparison of plotting the same search points
with different plot designs. The left plot doesn't efficiently use the
plot space to convey information from the plot while the right plot
provides good summarisation of data and number of points in each tries.}
\end{figure}

\hypertarget{a-more-complex-example-adding-an-interruption-in-the-interpolation-stage}{%
\subsubsection{A more complex example: adding an interruption in the
interpolation
stage}\label{a-more-complex-example-adding-an-interruption-in-the-interpolation-stage}}

\emph{Example: Interruption} This examples uses \texttt{search\_better}
for a 2D projection on the larger dataset using the \texttt{holes}
index. In the interpolation stage, continuous frames will be constructed
to bridge the project on the current basis to the target basis. The
target basis will become the current basis in the next iteration and the
searching stage continues to find the next target basis. In the left
panel of Figure \ref{interruption}, we observe that there are
interpolating bases with higher index values than the target basis and
these bases could be used to search for new basis in the next searching
stage.

An interruption is then constructed to accept the interpolating bases up
to the one with the largest index value and use that basis as the
current basis for the next searching stage. After implementing this
interruption, the tracing plot with the same configuration is shown on
the right panel of Figure \ref{interruption}. In the third
\texttt{tries}, rather than interpolating fully to the target basis at
\texttt{id\ =\ 62}, it stops before the index value starts to decrease
at \texttt{id\ =\ 60}. This implementation results in a higher index
value in the end with fewer steps.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/interruption-1.pdf}
\caption{\label{interruption}Trace plots of the interpolated basis with
and without the interruption. The interruption stops the interpolation
when the index value starts to decrease at id = 60. The implementation
of the interuption finds an ending basis with higher index value using
fewer steps.}
\end{figure}

\hypertarget{another-example-polishing-the-final-projection-basis}{%
\subsubsection{Another example: polishing the final projection
basis}\label{another-example-polishing-the-final-projection-basis}}

\emph{Example: Polish} In principle, all the optimisation routines
should result in the same output on the same problem while this may not
be true in real application. This motivates the creation of a polishing
search that polishes the ending basis and achieves unity on different
methods.

\texttt{search\_polish} takes the ending basis of a given search as the
current basis and uses a brutal-force approach to sample a large number
of basis (\texttt{n\_sample}) in the neighbourhood, whose radius is
controlled by \texttt{polish\_alpha}. Among the \texttt{n\_sample}
basis, the one with the largest index value becomes the candidate basis.
If its index value of the candidate basis is larger than that of the
current basis, it becomes the current basis in the next iteration. If no
basis is found to have larger index value than the current basis, the
searching neighbourhood will be shrunk and the search continues. The
polishing search ends when one of the four stopping criteria is
satisfied:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  the two basis can't be too close
\item
  the percentage improvement of the index function can't be too small
\item
  the searching neighbourhood can't be too small
\item
  the number of iteration can't exceed the \texttt{max.tries}
\end{enumerate}

{[}should the stopping criteria be more detailed? xxx{]}

The usage of search\_polish is as follows. After the first tour, the
final basis from the interpolation is extracted and supplied into a new
tour with the \texttt{start} argument and \texttt{search\_polish} as the
searching function in the guided\_tour. All the other arguments should
remain the same.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123456}\NormalTok{)}
\NormalTok{holes_2d_geo <-}\StringTok{ }\KeywordTok{animate_xy}\NormalTok{(data_mult[,}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{, }\DecValTok{7}\OperatorTok{:}\DecValTok{10}\NormalTok{)],}\DataTypeTok{tour_path =} 
                             \KeywordTok{guided_tour}\NormalTok{(}\KeywordTok{holes}\NormalTok{(), }\DataTypeTok{d =} \DecValTok{2}\NormalTok{, }
                                         \DataTypeTok{search_f =}\NormalTok{ tourr}\OperatorTok{:::}\NormalTok{search_geodesic),}
                           \DataTypeTok{rescale =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{verbose =} \OtherTok{TRUE}\NormalTok{)}

\NormalTok{last_basis <-}\StringTok{ }\NormalTok{holes_2d_geo }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(info }\OperatorTok{==}\StringTok{ "interpolation"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{tail}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{pull}\NormalTok{(basis) }\OperatorTok{%>%}\StringTok{ }\NormalTok{.[[}\DecValTok{1}\NormalTok{]]}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123456}\NormalTok{)}
\NormalTok{holes_2d_geo_polish <-}\StringTok{ }\KeywordTok{animate_xy}\NormalTok{(data_mult[,}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{, }\DecValTok{7}\OperatorTok{:}\DecValTok{10}\NormalTok{)], }\DataTypeTok{tour_path =} 
                                    \KeywordTok{guided_tour}\NormalTok{(}\KeywordTok{holes}\NormalTok{(), }\DataTypeTok{d =} \DecValTok{2}\NormalTok{, }
                                                \DataTypeTok{search_f =}\NormalTok{ tourr}\OperatorTok{:::}\NormalTok{search_polish),}
                                  \DataTypeTok{rescale =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{verbose =} \OtherTok{TRUE}\NormalTok{, }
                                  \DataTypeTok{start =}\NormalTok{ last_basis)}
\end{Highlighting}
\end{Shaded}

The following example conducted a 2D projection on the larger dataset
using search better with different configurations. \texttt{max.tries} is
a hyperparameter that controls the maximum number of try without
improvement and its default value is 25. As shown in Figure
\ref{trace-compare}, both trials attain the same index value after
polishing while a small \texttt{max.tries} of 25 is not sufficient for
\texttt{search\_better} to find the global maximum. The
\texttt{max.tries} argument needs to be adjusted to ensure it is
sufficient to explore the parameter space.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/polish-1.pdf}
\caption{\label{trace-compare}Breakdown of index value when using
different max.tries in search better in conjunction with search polish.
Both attain the same final index value after the polishing while using a
max.tries 25 is not sufficient to find the ture maximum.}
\end{figure}

\hypertarget{animated}{%
\subsection{Explore searching space}\label{animated}}

The parameter to explore can be a vector or matrix instead of scalar,
for example, the projection basis in tour. This imposes difficulties in
visualisation since humans are bounded to perceive at most three
dimensions in a plot. Thus, principal component analysis is used to
reduce the dimension of projection bases and the first two principal
components are mapped to the x and y axis of the plot. Additional
variable of interest could be mapped to the color aesthetics for
exploration.

\hypertarget{a-toy-example-understand-different-stage-of-search_geodesic}{%
\subsubsection{A toy example: understand different stage of
search\_geodesic}\label{a-toy-example-understand-different-stage-of-search_geodesic}}

\emph{Example: understand search\_geodesic} {[}feel like this example is
merely explaining search geodesic algorithm, so maybe introduce the
animated plot here? xxx{]} \texttt{search\_geodesic} is a two-stage
ascending algorithm with four different stages in the search and a PCA
plot useful to understand how the algorithm progresses and the relative
position of each basis in the PCA projected 2D space. Starting from the
start basis, a directional search is conducted in a narrow neighbourhood
on five random directions. The best one is picked and a line search is
then run on the geodesic direction to find the target basis. The
starting and target bases are then interpolated. In the next iteration,
the target basis becomes the current basis and then procedures
continues.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/pca-1.pdf}
\caption{\label{pca}PCA plot of search geodesic Coloring by info allows
for better understanding of each stage in the geodesic search}
\end{figure}

\hypertarget{a-more-complex-example-choosing-the-initial-value-for-polishing-parameter}{%
\subsubsection{A more complex example: Choosing the initial value for
polishing
parameter}\label{a-more-complex-example-choosing-the-initial-value-for-polishing-parameter}}

\emph{Example: initial value for polishing alpha}
\texttt{search\_polish} is a brutal-force algorithm that evaluate 1000
points in the neighbourhood at each loop. Setting an appropriate initial
value for polish\_alpha would avoid wasting search on large vector space
that are not likely to produce higher index value. The default initial
value for polishing step is 0.5 and we are interested in whether this is
an appropriate initial value to use after \texttt{search\_geodesic}. The
problem is a 1D projection of the small dataset using
\texttt{search\_geodesic} and followed by \texttt{search\_polish}. The
top-left panel of Figure \ref{polish-alpha} displays all the projection
bases on the first two principal components, colored by the
\texttt{polish\_alpha}. We can observe that rather than concentrating on
the ending basis from \texttt{search\_geodesic} as what polishing step
is designed, \texttt{search\_polish} searches a much larger vector
space, which is unnecessary. Thus a customised smaller initial value for
\texttt{polish\_alpha} would be ideal. One way to do this is to
initialised \texttt{polish\_alpha} as the projection distance between
the last two target bases. The top-right panel of Figure
\ref{polish-alpha} shows a more desirable concentrated searching space
near the ending basis. Both specifications of initial value allow the
searches to reach the same ending index values.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/polish-alpha-1.pdf}
\caption{\label{polish-alpha}PCA plot of two different polish alpha
initialisations. A default polish alpha = 0.5 searches a larger space
that is unncessary while a small customised initial value of polish
alpha will search near the ending basis. Both intialisations reach the
same ending index values.}
\end{figure}

\hypertarget{a-comprehensive-example-of-diagnosing-noisy-index-function}{%
\subsection{A comprehensive example of diagnosing noisy index
function}\label{a-comprehensive-example-of-diagnosing-noisy-index-function}}

\emph{Example: Noisy index function} The interpolation path of holes
index, as seen in Figure \ref{interruption}, is smooth, while this may
not be the case for more complicated index functions. \texttt{kol\_cdf}
index, an index function based on Kolmogorov test, compares the
difference between a projection matrix and a randomly generated normal
distribution based on cumulated distribution function (CDF). Several
diagnostic visualisations below show the characteristic of this index
function.

Figure \ref{kol-cdf} compares the tracing plot of the interpolating
points for \texttt{search\_geodesic} and \texttt{search\_better} on 1D
projection for \texttt{kol\_cdf} index and the interpolation path shows
a zig-zag pattern. Polishing step has done much more work to reach the
final index value for \texttt{search\_geodesic} than
\texttt{search\_better} and this indicates that noisy index's favour of
a random search method than ascent method {[}the order of the examples
needs to be rearranged since I haven't introduced polishing here.
xxx{]}.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/kol-cdf-1.pdf}
\caption{\label{kol-cdf}Comparison of two different searching methods:
search\_geodesic and search\_better on 1D projection problem for a
noisier index: kol\_cdf. The geodesic search rely heavily on the
polishing step to find the final index value while search better works
well.}
\end{figure}

The second example for \texttt{kol\_cdf} index uses 1D projection on the
larger dataset. Since there are two informative variables and the
projection is 1D, there are two local maximum when the projection matrix
at \([0, 1, 0, 0, 0, 0]\) and \([0, 0, 1 ,0, 0, 0]\). As in Figure
\ref{1d-2var-different-seeds}, different local maximum can be found
using \texttt{search\_better} with different seeds while
\texttt{search\_better\_random} can always find the global maximum, as
in Figure \ref{1d-2var-better-random}, although at a high cost of number
of points evaluated.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/1d-2var-different-seeds-1.pdf}
\caption{\label{1d-2var-different-seeds}The trace plot search better in
a 1D projection problem with two informative variables using different
seeds (without polishing). Since there are two informative variables,
setting different value for seed will lead search better to find either
of the local maximum.}
\end{figure}

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/1d-2var-better-random-1.pdf}
\caption{\label{1d-2var-better-random}Using search better random for the
problem above will result in finding the global maximum but much larger
number of iteration is needed.}
\end{figure}

\hypertarget{vis-package}{%
\section{Vis package}\label{vis-package}}

Everything is coded up in a package.

\clearpage

\bibliographystyle{agsm}
\bibliography{biblio.bib}

\end{document}
