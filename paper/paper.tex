% !TeX program = pdfLaTeX
\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage{textcomp}
\usepackage[hyphens]{url} % not crucial - just used below for the URL
\usepackage{hyperref}
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%

%% load any required packages here
\usepackage{amssymb, amsmath, mathtools, dsfont, bbm} \usepackage[ruled,vlined, linesnumbered]{algorithm2e}

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}



\begin{document}


\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if0\blind
{
  \title{\bf Title here}

  \author{
        Author 1 \thanks{The authors gratefully acknowledge \ldots{}} \\
    Department of YYY, University of XXX\\
     and \\     Author 2 \\
    Department of ZZZ, University of WWW\\
      }
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Title here}
  \end{center}
  \medskip
} \fi

\bigskip
\begin{abstract}
Friedman \& Tukey commented on their initial paper on projection pursuit
in 1974 that ``the technique used for maximising the projection index
strongly influences both the statistical and the computational aspects
of the procedure.'' While many projection pursuit indices have been
proposed in the literature, few concerns the optimisation procedure. In
this paper, we developed a system of diagnostics aiming to visually
learn how the optimisation procedures find its way towards the optimum.
This diagnostic system can be applied to more generally to help
practitioner to unveil the black-box in randomised iterative
(optimisation) algorithms. An R package, ferrn, has been created to
implement this diagnostic system.
\end{abstract}

\noindent%
{\it Keywords:} optimisation, projection pursuit, guided tourr, visual, diagnostics, R
\vfill

\newpage
\spacingset{1.45} % DON'T change the spacing!

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Visualisation has been widely used in exploratory data analysis.
Presenting information in a graphical format often allows people to see
information they would otherwise not see. This motivates our work of
creating plots to diagnose optimisation algorithms in the context of
projection pursuit guided tour, with the aim to understand and compare
features of different existing algorithms.

In an optimization problem the goal is to find the best solution within
the space of all feasible solutions which typically is represented by a
set of constraints. The problem consists in optimizing an objective
function \(f: S \rightarrow \mathbb{R}\) with \(S \in \mathbb{R}^n\) in
a reduced space given by the problem constraints to either minimize or
maximize a function.

Projection pursuit and guided tour are exploratory data analysis tools
that detect interesting structure of high dimensional data through
projection on low dimensional space. Optimisation is applied here to
search for the low dimensional space that finds the most interesting
projection.

The remainder of the paper is organised as follows. Section \ref{optim}
provides the literature review of optimisation methods, specifically the
line search methods used in projection pursuit guided tour. Section
\ref{tour} reviews projection pursuit guided tour, forms the
optimisation problem, and introduces three main existing algorithms.
Section \ref{vis-diag} presents the new visual diagnostics design, from
forming the data object to the definition of different diagnostic plots
with some small examples. Section \ref{application} shows the
applicaiton of how the diagnostic plots designed in section
\ref{vis-diag} can be used to understand and compare different
algorithms and how they contribute to modifications that improve the
algorithms. Finally, Section \ref{implementation} describes the R
package: ferrn, that implements all the visual diagnostics above.

\newpage

\hypertarget{optim}{%
\section{Optimisation Methods}\label{optim}}

Given an optimisation problem, two basic approaches find the optimum
based on different thinking. An analytical approach aims to find the
optimal solution in a finite number of steps, but a potential issue with
it is that the close-form solution may not be available when the problem
starts to become complex. An iterative approach, on the other hand,
finds the optimum based on the idea of making progressive improvement to
the current solution. An iterative method may end up finding a local
optimum but the progressive nature of the algorithm allows the
practitioner to decide when to stop if a desirable accuracy has been
achieved.

A traditional while often used in practice is an iteartive method called
\emph{line search method} \citep{fletcher2013practical}. In a simple
one-dimensional problem of finding the \(x\) that minimises \(f(x)\),
line search achieves the goal via an iterative algorithm in the form of
Equation \ref{eq:line-search}.

\begin{equation}
x^{(j + 1)} = x^{(j)} + \alpha_k* d^{(j)}
\label{eq:line-search}
\end{equation}

where \(d^{(j)}\) is the searching direction in iteration \(j\), and
\(\alpha_j\) is the step-size. Strictly speaking, \(\alpha_k\) is chosen
by another minimisation of \(f(x^{(j)} + \alpha* d^{(j)})\) with respect
to \(\alpha\) and theoretical results have demonstrated the global
convergence of the algorithm when the exact minimisation of \(\alpha_j\)
is attained \citep{curry1944method}. In practice, this second
minimisation is rarely implemented due to its computational demanding or
even the existence of such a minimisation. A more realistic approach is
to impose a mandatory decrease in the objective function for each
iteration: \(f^{(j+1)}> f^{(j)}\) and despite we lose the guarantee on
global convergence, this approach turns out to be efficient in practical
problems.

{[}Are we using projection pursuit/guided tour to better understand the
convergence of optimization algorithms visually in combination with the
algorithms discussed below? Or we are focusing on the optimisation
problem only within the projection pursuit context? Some of the problems
listed below are also applicable to optimization problem in general too.
ppp{]}

\newpage

\hypertarget{tour}{%
\section{Projection pursuit guided tour}\label{tour}}

Modern development of the line search methods focuses on proposing
different computation on the seraching direction: \(d^{(j)}\) and
various approximations on the step size: \(\alpha_j\) catered for
practical optimisation problems. The specific problem context we are
interested in is called projection pursuit guided tour. Projection
pursuit and guided tour are two separate methods in exporatory data
analysis focusing on different aspects: coined by
\citet{friedman1974projection}, projection pursuit detects interesting
structures (i.e.~clustering, outliers and skewness) in multivariate data
via low dimensions projection; whilst guided tour is a particular
variation in a broader class of data visualisation method called tour.

Let \(\mathbf{X}_{n \times p}\) be the data matrix, an n-d projection
can be seen as a linear transformation
\(T: \mathbb{R}^p \mapsto \mathbb{R}^d\) defined by
\(\mathbf{P} = \mathbf{X} \cdot \mathbf{A}\), where
\(\mathbf{P}_{n \times d}\) is the projected data and
\(\mathbf{A}_{p\times d}\) is the projection basis. Define
\(f: \mathbb{R}^{p \times d} \mapsto \mathbb{R}\) to be an index
function that maps the projection basis \(\mathbf{A}\) onto an index
value \(I\), this function is commonly known as the projection pursuit
index (PPI) function, or the index function and is used to measure the
``interestingness'' of a projection. A number of index functions have
been proposed in the literature to detect different data structures,
including Legendre index \citep{friedman1974projection}, Hermite index
\citep{hall1989polynomial}, natural Hermite index
\citep{cook1993projection}, chi-square index
\citep{posse1995projection}, LDA index \citep{lee2005projection} and PDA
index \citep{lee2010projection}.

In their initial paper, \citet{friedman1974projection} noted that
``\ldots{}, the technique used for maximising the projection index
strongly influences both the statistical and the computational aspects
of the procedure.'' Hence, effective optimisation algorithms are
necessary for projection pursuit to find the bases that give interesting
projections. While we leave the formal construction of the optimisation
problem and existing algorithms to section \ref{tour-optim}, we outline
the general idea here. Given a random starting (current) basis,
projection pursuit repeatedly searches for candidate bases nearby until
it finds one with higher index value than the current basis. In the
second round, that basis becomes the current basis and the repetitive
sampling continues. The process ends until no better basis can be found
or one of the termination criteria is reached.

Before introducing the guided tour, we shall be familiar with the
general tour method \citep{cook2008grand}. A tour produces animated
visualisation of the high dimensional data via rotating low dimension
planes. The smoothness of the animation is ensured by computing a series
of intermediate planes between two low dimension planes via geodesic
interpolation and we refer readers to \citet{buja2005computational} for
the mathematical details. Iteratively choose different low dimension
planes and interpolate between them forms a tour path. Different types
of tour methods choose the low dimensional planes differently and we
mention two other type of tour that are commonly used. A grand tour
selects the planes randomly in the high dimensional space and hence
serves as an initial exploration of the data. Manual control allows
researches to fine-tuning an existing projection by gradually phase in
and out one variable.

Guided tour chooses the planes produced by optimising the projection
pursuit index function. Figure \ref{tour-path} shows a sketch of the
tour path consisting of the blue frames produced by the projection
pursuit optimisation algorithm iteratively and the white frames, which
are the interpolations between two blue frames. The tour method has been
implemented in the \emph{tourr} package in R, available on the
Comprehensive R Archive Network at
\url{https://cran.r-project.org/web/packages/tourr/}
\citep{wickham2011tourrpackage}.

\begin{figure}
\includegraphics[width=1\linewidth,height=0.6\textheight]{/Users/hzha400/Documents/3.PhD/research/paper-tour-vis/figures/tour_path_keynote/tour_path_keynote.001} \caption{\label{tour-path}An illustration of the tour path}\label{fig:tour-path}
\end{figure}

\newpage

\hypertarget{tour-optim}{%
\subsection{Optimisation problem}\label{tour-optim}}

Now we begin to formulate the optimisation problem. Given a randomly
generated starting basis \(\mathbf{A}_1\), projection pursuit finds the
final projection basis
\(\mathbf{A}_T = [\mathbf{a}_1, \cdots, \mathbf{a}_d]\), where
\(\mathbf{a}_i \in \mathbb{R}^{p}\), satisfies the following
optimisation problem:

\begin{align}
&\arg \max_{\mathbf{A} \in \mathcal{A}} f(\mathbf{X} \cdot \mathbf{A}) \\
s.t. &  \langle \mathbf{a}_i, \mathbf{a}_j \rangle = \delta_{ij}, \forall \mathbf{a}_i, \mathbf{a}_j \in \mathbf{A}
\end{align}

Where \(\delta_{ij}\) is the kronecker delta that takes 1 if \(i = j\)
and 0 otherwise.

There are several features of this optimisation that are worth noticing.
First of all, it is a multivariate constraint optimisation problem.
Since the decision variables are the entries of a projection basis, it
is required to be orthonormal. It is also likely that the objective
function is non-differentiable or the gradient information is simply not
available. In this case, we will need to either use some approximation
of the gradient or turn to derivative free methods. Given the goal of
projection pursuit as finding the basis with the largest index value,
the optimisation problem need to be able to find the global maximum.
Along the way, locla maximum may also be of our interest since they
could present unexpected interesting projections. There is also one
computational consideration: the optimisation procedure needs to be easy
to compute since the tour animation is played in real-time.

\newpage

\hypertarget{existing-algorithms}{%
\subsection{Existing algorithms}\label{existing-algorithms}}

Below we introduce three possible algorithms: \texttt{search\_better}
and \texttt{search\_better\_random} are derivative free methods that
sample candidate basis in the neighbourhood whilst
\texttt{search\_geodesic} approximates the gradient information and acts
as a non-derivative version of the gradient acsent.

\citet{posse1995projection} proposed a random search algorithm that
samples a candidate basis \(\mathbf{A}_{l}\) in the neighbourhood of the
current basis \(\mathbf{A}_{\text{cur}}\) by
\(\mathbf{A}_{l} = \mathbf{A}_{\text{cur}} + \alpha \mathbf{A}_{rand}\),
where \(\alpha\) controls the radius of the sampling neighbourhood and
\(\mathbf{A}_{\text{rand}}\) is a randomly generated matrix with the
same dimension as \(\mathbf{A}_{\text{cur}}\). The optimiser keeps
sampling bases near the current basis until it finds one with higher
index value than the current basis and then outputs it for guided tour
to construct the interpolation path. A new round of search continues to
find a better basis after the interpolation finishes. The halving
parameter \(c\) with default value of 30 is designed to adjust the
searching neighbourhood \(\alpha\). When the search needs to sample more
than \(c\) number of basis to find an accpeted basis, the neighbourhood
parameter \(\alpha\) will be reduced by half in the next iteration. If
the optimiser can't find a better basis within the maximum number of
tries \(l_{\max}\), the algorithm stops. The algorithm is summarised in
Algorithm \ref{random-search} for one iteration. {[}mention
orthonormalise to ensure the constaint is fulfilled; don't use
derivative information but a random search{]}

\begin{algorithm}
\SetAlgoLined
  \SetKwInOut{Input}{input}
  \SetKwInOut{Output}{output}
    \Input{$\mathbf{A}_{\text{cur}}$, $f$, $\alpha$, $l_{\max}$} 
    \Output{$\mathbf{A}_{l}$}
  initialisation\;
  Set $l = 1$ and $c = 0$\;
  \While{$l < l_{\max}$}{
    Generate $\mathbf{A}_{l} = \mathbf{A}_{\text{cur}} + \alpha \mathbf{A}_{\text{rand}}$ and orthonormalise $\mathbf{A}_{l}$\;
    Compute $I_{l}  = f(\mathbf{A}_{l})$\;
    \eIf{$I_{l} > I_{\text{cur}}$}{
      \KwRet{$\mathbf{A}_{l}$} \;
      }{
      $c = c + 1$\;
      }
    $l = l + 1$\;
  }
  We repeat this loop and if $c > 30$, half the $\alpha$. Reset $c$ to zero.
  \caption{random search}
  \label{random-search}
\end{algorithm}

Simulated annealing
\citep[\citet{kirkpatrick1983optimization}]{bertsimas1993simulated}
modifies \texttt{search\_better} based on a non-increasing cooling
scheme \(T(j)\). Given an initial \(T_0\), the temperature at iteration
\(k\) is defined as \(T(j) = \frac{T_0}{\log(j + 1)}\). When a candidate
basis fails to have an index value larger than the current basis,
simulated annealing gives it a second chance to be accepted with
probabiliby
\[P= \min\left\{\exp\left[-\frac{I_{cur} - I_{j}}{T(j)}\right],1\right\}\]
where \(I_{(\cdot)}\) denotes the index value of a given basis. This
implementation allows the algorithm to jump out of a local maximum and
enables a more holistic search of the whole parameter space. This
feature is particularly useful when the dimension of the projected space
is smaller than the number of informative variables in the dataset
(i.e.~a one dimenional projection of the dataset with two informative
variables). The algorithm can be written as replacing line 5-11 of
Algorithm \ref{random-search} with Algorithm \ref{simulated_annealing}.

\begin{algorithm}
\SetAlgoLined
    Compute $I_{j} = f(\mathbf{A}_{j})$ and $T(k) = \frac{T_0}{\log(j + 1)}$\;
      \eIf{$I_{j} > I_{\text{cur}}$}{
        \KwRet{$\mathbf{A}_{j}$} \;
      }{
        Compute $P= \min\left\{\exp\left[-\frac{I_{\text{cur}} -I_{j}}{T(j)}\right],1\right\}$\;
        Draw $U$ from a uniform distribution: $U \sim \text{Unif(0, 1)}$\;
        \If{$P > U$}{
           \KwRet{$\mathbf{A}_{j}$} \;
        }
      }
  \caption{simulated annealing}
  \label{simulated_annealing}
\end{algorithm}

\citet{cook1995grand} used a gradient ascent algorithm with
pseudo-derivative. Instead of computing the actual gradient of the index
function with respect to the projection basis matrix,
\texttt{search\_geodesic} samples \(2n\) bases that are randomly
generated on a uniform open ball with the radius controlled by the
\(\delta\) parameter and finds the most promising one to construct the
geodesic direction as an approximation to the graident. The \(\delta\)
parameter is usually set to be tiny to ensure the geogesic direction is
a good local approximation to the graident. Once the searching direction
is determined, the optimiser finds the best projection
\(\mathbf{A}_{**}\) on the geodesic as the candidate.
\(\mathbf{A}_{**}\) is outputted for the current iteration if the
percentage change in the index value between \(\mathbf{A}_{**}\) and
\(\mathbf{A}_{\text{cur}}\) is greater than a threshold value or the
algorithm repeats the above steps until \(l_{\max}\) is reached and the
searching terminates. Algorithm \ref{search-geodesic} summarise the
steps in geodesic search.

\begin{algorithm}
\SetAlgoLined
\SetKwInOut{Input}{input}
  \SetKwInOut{Output}{output}
    \Input{$\mathbf{A}_{\text{cur}}$, $f$, $j_{\max}$, $n$, $\delta$}
    \Output{$\mathbf{A}_{**}$}
  initialisation\;
  Set $j = 1$\;
  \While{$j < j_{\max}$}{
    Generate $2n$ bases in $n$ random directions: $\mathbf{A}_{j}: \mathbf{A}_{j+9}$ within a small neighbourhood $\delta$\;
    Find the direction with the largest index value: $\mathbf{A}_{*}$ where $j < * < j+ 9$\;
    Construct the geodesic $\mathcal{G}$ from $\mathbf{A}_{\text{cur}}$ to $\mathbf{A}_{*}$\;
    Find $\mathbf{A}_{**}$ on the geodesic $\mathcal{G}$ that has the largest index value \;
    Compute $I_{**} = f(\mathbf{A}_{**})$, $p_{\text{diff}} = (I_{**} - I_{\text{cur}})/I_{**}$\;
      \If{$p_{\text{diff}} > 0.001$}{
         \KwRet{$\mathbf{A}_{**}$} \;
      }
    $j = j + 1$\;
  }
  \caption{search geodesic}
  \label{search-geodesic}
\end{algorithm}

\newpage

\hypertarget{vis-diag}{%
\section{Visual diagnostics}\label{vis-diag}}

\hypertarget{global-object}{%
\subsection{Global object}\label{global-object}}

The idea of generalised framework for diagnostic plots is inspired by
the concept of grammar of graphic \citep{wickham2010layered}, which
powers the primary graphical system in R, ggplot2 \citep{ggplot2}. In
grammar of graphic, plots are not defined by its appearance
(i.e.~boxplot, histogram, scatter plot etc) but by ``stacked layers''.
Using this design, ggplot does not have to develop a gazillion of
functions that each produces a different type of plot from a different
data structure. Instead, it aesthetically maps variables (and its
statistical transformation) in a dataset to different geometric objects
(points, lines, box-and-whisker etc) and builds the plot through
overlaying different layers.

There are different ways to represent the same data in rectangular form.
Certain cleaning steps are needed, before using ggplot2, to bring the
data into a tidy data format \citep{wickham2014tidy} where 1) each
observation forms a row; 2) each variable forms a column and 3) each
type of observational unit forms a table. In a tidy format, data
wrangling and visualisation are greatly simplified.

Global object is a data construction with key components from
optimisation algorithms and is designed for making diagnostic plots
easier. In the optimisation algorithms for projection pursuit, three key
elements are 1) projection bases: \(\mathbf{A}\), 2) index values: \(I\)
and 3) State: \(S\), which labels the observation with detailed stage of
searching or interpolation.

Multiple iterators are needed to index the data collected at different
levels. \(t\) is a unique identifier that prescribes the natural
ordering of each observation; \(j\) is the counter for each
search-and-interpolate round, which remains the same within one round
and has an increment of one once a new round starts. \(l\) is the
counter for each search/interpolation allowing us to know how many basis
the algorithm has searched before finding one to output.

There are other parameters that are of our interest and we denote them
as \emph{\(V_{p}\)}. In projection pursuit, this includes
\(V_1 = \text{method}\), which tags the name of the algorithm used and
\(V_2 = \text{alpha}\), the neighbourhood parameter that controls the
size in sampling candidate bases. The data structure can thus be shown
as in Equation \ref{eq:data-structure}.

\begin{equation}
\left[
\begin{array}{c|ccc|cc|cc}
t & \mathbf{A} & I & S & j &  l  & V_{1} & V_{2}\\
\hline
1 & \mathbf{A}_1 & I_1 & S_1 & 1 & 1 & V_{11} & V_{12}\\
\hline
2 & \mathbf{A}_2 & I_2 & S_2 & 2 & 1  & V_{21}  & V_{22}\\
3 & \mathbf{A}_3 & I_3 & S_3 & 2 & 2  & V_{31}  & V_{32}\\
\vdots & \vdots &\vdots &\vdots  &\vdots & \vdots &\vdots  &\vdots\\
\vdots & \vdots & \vdots &\vdots & 2 & l_2 & \vdots  & \vdots\\
\hline
\vdots &\vdots & \vdots &\vdots & 2  & 1& \vdots & \vdots\\
\vdots &\vdots &\vdots &\vdots & 2 & 2& \vdots &  \vdots\\
\vdots &\vdots &\vdots &\vdots &\vdots & \vdots & \vdots  &\vdots \\
\vdots &\vdots &\vdots &\vdots & 2 & k_2 &\vdots  & \vdots\\
\hline
\vdots &\vdots &\vdots &\vdots &\vdots & \vdots &\vdots &\vdots \\
\hline
\vdots & \vdots & \vdots &\vdots  & J &  1 & \vdots & \vdots \\
\vdots &\vdots &\vdots &\vdots &\vdots & \vdots &\vdots &\vdots \\
T & \mathbf{A}_T & I_T &S_T  & J &  l_{J} & V_{T1}& V_{T2}\\
\hline
\vdots &\vdots & \vdots &\vdots & J  & 1& \vdots & \vdots\\
\vdots &\vdots &\vdots &\vdots &\vdots & \vdots & \vdots  &\vdots \\
\vdots &\vdots &\vdots &\vdots & J & k_J &\vdots  & \vdots\\
\hline
\vdots& \vdots & \vdots & \vdots & J+1 & 1 & \vdots& \vdots\\
\vdots &\vdots &\vdots &\vdots &\vdots & \vdots &\vdots &\vdots \\
T^\prime & \mathbf{A}_{T^\prime} & I_{T^\prime} &S_{T^\prime}  & J+1 &  l_{J+1} & V_{T^\prime 1}& V_{T^\prime 2}\\
\end{array}
\right]
= 
\left[
\begin{array}{c}
\text{column name} \\
\hline
\text{search (start basis)} \\
\hline
\text{search} \\
\text{search} \\
\vdots \\
\text{search (accepted basis)} \\
\hline
\text{interpolate} \\
\text{interpolate} \\
\vdots \\
\text{interpolate} \\
\hline
\vdots \\
\hline
\text{search} \\
\vdots \\
\text{search (final basis)} \\
\hline
\text{interpolate} \\
\vdots \\
\text{interpolate} \\
\hline
\text{search (no output)} \\
\vdots \\
\text{search (no output)} \\
\end{array}
\right]
\label{eq:data-structure}
\end{equation}

where \(T^{\prime} = T + k_{J}+ l_{J+1}\). Note that we deliberately
denote the last round of search as \(j = J+1\) and in that round there
is no output/interpolation basis and the algorithm terminates. This
notation allows us to denote the last complete search-and-interpolate
round as round \(J\) and hence the final basis is \(A_T\) and highest
index value found is \(I_T\).

{[}outside the paper: I find the notation of current/target basis is
confusing because the target basis in round \(j\) becomes the current
basis in round \(j+1\). Also, when we start to have polish, the target
basis may not be the current basis in the next round\ldots{} The place
where current/target is most appropriate is probably when describing the
interpolation where the first one is always the current basis and the
last is always the target basis. I think it is better to leave this
language in the code{]}

A sketch of the global object for projection pursuit guided tour is
presented in Figure \ref{fig:glb-obj}.

{[}I feel this sketch was initially useful but now since we have the
data matrix and the printed output of the global object, it doesn't any
additional information. I'm still keeping it here but we may need to
remove it if it's not useful :({]}

\begin{figure}
\includegraphics[width=1\linewidth,height=0.2\textheight]{/Users/hzha400/Documents/3.PhD/research/paper-tour-vis/figures/global_obj} \caption{\label{glb-obj}The global object in projection pursuit guided tour.}\label{fig:glb-obj}
\end{figure}

\hypertarget{plot-definition}{%
\subsection{Plot definition}\label{plot-definition}}

Since the global object is already tidy, not further tidying steps is
needed, while certain data wrangling steps
\citep{wickham2016rfordatascience} are still needed to transform the
global object into desirable format for one particular visualisation. To
emphasize on this good practice of data analysis, we will describe the
transformation steps needed for each diagnostic plots before stepping
into visualisation.

\hypertarget{static}{%
\subsubsection{Explore the value of objective function}\label{static}}

\hypertarget{searching-points}{%
\paragraph{Searching points}\label{searching-points}}

A primary interest of diagnosing an optimisation algorithm is to study
how it finds its optimum progressively. We could plot the index value
across its natural ordering, however, different iterations may have
different number of points and, towards the end of the search there
could easily be hundreds of bases being tested before the target basis
is found. In the plot, points from those iterations towards the end will
occupy the vast majority of the plot space. This motivates to use
summarisation. Rather than knowing the index value of \emph{every}
basis, we are more interested to have a general summary of all the index
value in that iteration and more importantly, the basis with the largest
index value (since it prescribes the next geodesic interpolation and
future searches).

Boxplot is a suitable candidate that provides five points summary of the
data, however it has one drawback: it does not report the number of
points in each box. We may risk losing information on how many points it
takes to find the target basis by displaying the boxplot alone for all
\texttt{tries}. Thus, the number of point in each iteration is displayed
at the bottom of each box and we provide options to switch iteration
with small number of points to a point geometry, which is achieved via a
\texttt{cutoff} argument. A line geometry is also added to link the
points with the largest index value in each iteration. This helps to
visualise the improvement made in each iteration. Using the concept of
\emph{gramma of graphics} \citep{wickham2010layered}, the plot for
exploring index value can be defined in three layers as:

\begin{itemize}
\tightlist
\item
  Layer 1: boxplot geom

  \begin{itemize}
  \tightlist
  \item
    data: group by \(j\) and filter the observations in the group that
    have count greater than \texttt{cutoff\ =\ 15}.
  \item
    x: \(j\) is mapped to the x-axis
  \item
    y: the statistical transformed index value: \(Q_{I^{\prime}_t}(q)\)
    is mapped to the y-axis where \(Q_X(q)\), \(q = 0, 25, 50, 75, 100\)
    finds the qth-quantile of \(X\) and \(I^{\prime}_t\) denotes the
    index value of all the searching bases defined in Matrix
    \ref{eq:data-structure}.
  \end{itemize}
\item
  Layer 2: point geom

  \begin{itemize}
  \tightlist
  \item
    data: group by \(j\) and filter the observations in the group that
    have count less than \texttt{cutoff\ =\ 15}.
  \item
    x: \(j\) is mapped to the x-axis
  \item
    y: \(I\) is mapped to the y-axis
  \end{itemize}
\item
  Layer 3: line geom

  \begin{itemize}
  \tightlist
  \item
    data: filter the points with the highest index value in group \(j\)
  \item
    x: \(j\) is mapped to the x-axis
  \item
    y: \(I\) is mapped to the y-axis
  \end{itemize}
\end{itemize}

\hypertarget{toy-example-exploring-searching-points}{%
\subparagraph{Toy example: exploring searching
points}\label{toy-example-exploring-searching-points}}

We choose variables \texttt{x1}, \texttt{x2}, \texttt{x3}, \texttt{x8},
\texttt{x9} and \texttt{x10} to perform a 2D projection with tour.
Parameter \texttt{search\_f\ =\ tour::search\_better} and
\texttt{max.tries\ =\ 500} is used. The index value of the searching
points are shown in Figure \ref{points}. The label at the bottom
indicates the number of observations in each iteration and facilitates
the choice of \texttt{cutoff} argument (by default
\texttt{cutoff\ =\ 15}). We learn that the \texttt{search\_better}
quickly finds better projection basis with higher index value at first
and then takes longer to find a better one later.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/points-tries-1.pdf}
\caption{\label{points}A comparison of plotting the same search points
with different plot designs. The left plot does not use the plot space
efficiently to convey information from the plot while the right plot
provides good summarisation of data and number of points in each tries.}
\end{figure}

\hypertarget{interpolating-points}{%
\paragraph{Interpolating points}\label{interpolating-points}}

Sometimes, rather than exploring the searching points, we may be
interested in exploring the points on the interpolation path (target and
interpolating points) since these points will be played by the tour
animation. Since interpolation paths are geodesically the shortest, a
summarisation using boxplot geometry is no longer needed. The slightly
modified plot definition is shown below:

\begin{itemize}
\tightlist
\item
  Layer 1: point geom

  \begin{itemize}
  \tightlist
  \item
    data: filter the observations with \(S = \text{interpolation}\) and
    mutate \(t\) to be the row number of the subsetted tibble
  \item
    x: \(t\) is mapped to the x-axis
  \item
    y: \(I\) is mapped to the y-axis
  \end{itemize}
\item
  Layer 2: line geom

  \begin{itemize}
  \tightlist
  \item
    using line geometry for the same data and aesthetics
  \end{itemize}
\end{itemize}

\hypertarget{toy-example}{%
\subparagraph{Toy example}\label{toy-example}}

\hypertarget{explore-searching-space}{%
\subsubsection{Explore searching space}\label{explore-searching-space}}

In projection pursuit, the projection bases \(\mathbf{A}_{p \times d}\)
are usually of dimension \(p \times d\) and hence can't be visualised in
a 2D plot. An option to explore the searching space of these bases is to
explore a reduced space via principal component analysis (PCA). The
visualisation can thus be defined as

\begin{itemize}
\tightlist
\item
  Layer 1: point geom

  \begin{itemize}
  \tightlist
  \item
    data: subset the basis of interest and arrange into a matrix format;
    perform PCA on the basis matrix and compute the projected basis on
    the first two principal components; bind the variables from the
    original global object and form a tibble
  \item
    x: the projected basis on the first principal component
  \item
    y: the projected basis on the second principal component
  \item
    colour: \(V\) is mapped to the colour aesthetic
  \end{itemize}
\end{itemize}

\hypertarget{a-toy-example-understand-different-stage-of-search_geodesic}{%
\paragraph{A toy example: understand different stage of
search\_geodesic}\label{a-toy-example-understand-different-stage-of-search_geodesic}}

\texttt{search\_geodesic} is a two-stage ascending algorithm with four
different stages in the search and a PCA plot useful to understand how
the algorithm progresses and the relative position of each basis in the
PCA projected 2D space. Starting from the start basis, a directional
search is conducted in a narrow neighbourhood on five random directions.
The best one is picked and a line search is then run on the geodesic
direction to find the target basis. The starting and target bases are
then interpolated. In the next iteration, the target basis becomes the
current basis and then the procedures continues.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/pca-1.pdf}
\caption{\label{pca}PCA plot of search geodesic colouring by info allows
for better understanding of each stage in the geodesic search}
\end{figure}

\newpage

\hypertarget{application}{%
\section{Application}\label{application}}

Below we will present several examples of diagnosing different aspects
of the projection pursuit optimisation. We will present more examples
that can help us to understand the algorithm and parameter choice:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  \ldots{}
\item
  \ldots{}
\item
  \ldots{}
\item
  \ldots{}
\end{enumerate}

Remember the research question we raised earlier, the purpose of visual
diagnostics is to understand:

\begin{itemize}
\item
  Whether the algorithm has successfully found the maximum and how the
  index value changes throughout the algorithm?
\item
  How does the searching space look like, that is, geometrically, where
  are the projection bases located in the space?
\end{itemize}

(mention optim difficulties and split the simulated data section into
the examples!!!)

We simulate some random variables of size 1000 with different
structures. \texttt{x1}, \texttt{x8}, \texttt{x9} and \texttt{x10} are
simulated from normal distribution with zero mean and variance of one as
in equation \ref{eq:sim-norm}. When using projection pursuit to explore
the data structure based on its departure from normality, the entry in
the projection basis for these variables should be close to zero in
theory. \texttt{x2} to \texttt{x7} are mixture of normal distributions
with different weights and locations. Equation \ref{eq:sim-x2} to
\ref{eq:sim-x7} outlines the distribution where each variable is
simulated from and Figure \ref{origin-data} shows the histogram of each
variable except \texttt{x3}. All the variables are then scaled to have
unit variance before running the projection pursuit.

\begin{align}
x_1 \overset{d}{=} x_8 \overset{d}{=} x_9 \overset{d}{=} x_{10}& \sim \mathcal{N}(0, 1) \label{eq:sim-norm} \\
x_2 &\sim 0.5 \mathcal{N}(-3, 1) + 0.5 \mathcal{N}(3, 1)\label{eq:sim-x2}\\
\Pr(x_3) &= 
\begin{cases}
0.5 & \text{if $x_3 = -1$ or $1$}\\
0 & \text{otherwise}
\end{cases}\label{eq:sim-x3}\\
x_4 &\sim 0.25 \mathcal{N}(-3, 1) + 0.75 \mathcal{N}(3, 1) \label{eq:sim-x4}\\
x_5 &\sim \frac{1}{3} \mathcal{N}(-5, 1) + \frac{1}{3} \mathcal{N}(0, 1) + \frac{1}{3} \mathcal{N}(5, 1)\label{eq:sim-x5}\\
x_6 &\sim 0.45 \mathcal{N}(-5, 1) + 0.1 \mathcal{N}(0, 1) + 0.45 \mathcal{N}(5, 1)\label{eq:sim-x6}\\
x_7 &\sim 0.5 \mathcal{N}(-5, 1) + 0.5 \mathcal{N}(5, 1) 
\label{eq:sim-x7}
\end{align}

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/origin-data-1.pdf}
\caption{\label{origin-data} The distribution of simulated data except
x3}
\end{figure}

We form our first dataset using variables \texttt{x1}, \texttt{x2},
\texttt{x8}, \texttt{x9} and \texttt{x10}, run the guided tour with
optimiser \texttt{search\_better} and below shows the first ten rows of
the global object.

{[}I notice that in the implementation the loop index for interpolation
starts from 0 rather than 1. Need more investigation to see if it is
easy to change it to 1 or we will have to change the definition of the
data structure.{]}

\begin{verbatim}
## # A tibble: 10 x 8
##       id basis             index_val info         tries  loop method       alpha
##    <int> <list>                <dbl> <chr>        <dbl> <dbl> <chr>        <dbl>
##  1     1 <dbl[,1] [5 x 1]>     0.749 new_basis        1     1 <NA>           0.5
##  2     2 <dbl[,1] [5 x 1]>     0.730 random_sear~     2     1 search_bett~   0.5
##  3     3 <dbl[,1] [5 x 1]>     0.743 random_sear~     2     2 search_bett~   0.5
##  4     4 <dbl[,1] [5 x 1]>     0.736 random_sear~     2     3 search_bett~   0.5
##  5     5 <dbl[,1] [5 x 1]>     0.747 random_sear~     2     4 search_bett~   0.5
##  6     6 <dbl[,1] [5 x 1]>     0.725 random_sear~     2     5 search_bett~   0.5
##  7     7 <dbl[,1] [5 x 1]>     0.752 new_basis        2     6 search_bett~   0.5
##  8     8 <dbl[,1] [5 x 1]>     0.749 interpolati~     2     0 search_bett~  NA  
##  9     9 <dbl[,1] [5 x 1]>     0.750 interpolati~     2     1 search_bett~  NA  
## 10    10 <dbl[,1] [5 x 1]>     0.750 interpolati~     2     2 search_bett~  NA
\end{verbatim}

\hypertarget{a-more-complex-example-interruption}{%
\subsection{A more complex example:
Interruption}\label{a-more-complex-example-interruption}}

We use the same dataset as the toy example above to explore the search
function \texttt{search\_better} and we want to learn how the index
value changes on the interpolation path for the \texttt{holes} index.
From the left panel of Figure \ref{interruption}, we observe that when
interpolating from the current basis to the target basis, the index
value may not be monotone: we could reach a basis with a higher index
value than the target basis on the interpolation path. In this sense, we
would be better off using the basis with the highest index value on the
interpolation path as the current basis for the next iteration (rather
than using the target basis). Hence, an interruption is constructed to
accept the interpolating bases only up to the one with the largest index
value. After implementing this interruption, the search finds higher
final index value with fewer steps as shown in the right panel of Figure
\ref{interruption}.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/interruption-1.pdf}
\caption{\label{interruption}Trace plots of the interpolated basis with
and without interruption. The interruption stops the interpolation when
the index value starts to decrease at id = 60. The implementation of the
interuption finds an ending basis with higher index value using fewer
steps.}
\end{figure}

\hypertarget{another-example-polish}{%
\subsection{Another example: Polish}\label{another-example-polish}}

In principle, all the optimisation routines should result in the same
output for the same problem while this may not be the case in real
application. This motivates the creation of a polishing search that
polishes the final basis found and achieves unity across different
methods.

\texttt{search\_polish} takes the final basis of a given search as a
start and uses a brutal-force approach to sample a large number of basis
(\texttt{n\_sample}) in the neighbourhood. Among those sampled basis,
the one with the largest index value is chosen to be compared with the
current basis. If its index value is larger than that of the current
basis, it becomes the current basis in the next iteration. If no basis
is found to have larger index value, the searching neighbourhood will
shrink and the search continues. The polishing search ends when one of
the four stopping criteria is satisfied:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  the chosen basis can't be too close to the current basis
\item
  the percentage improvement of the index value can't be too small
\item
  the searching neighbourhood can't be too small
\item
  the number of iteration can't exceed \texttt{max.tries}
\end{enumerate}

The usage of search\_polish is as follows. After the first search, the
final basis from the interpolation is extracted and supplied to the
second search as the \texttt{start} argument. \texttt{search\_polish} is
used as the search function. All the other arguments should remain the
same.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123456}\NormalTok{)}
\NormalTok{holes_2d_geo <-}\StringTok{ }\KeywordTok{animate_xy}\NormalTok{(data_mult[,}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{, }\DecValTok{7}\OperatorTok{:}\DecValTok{10}\NormalTok{)],}\DataTypeTok{tour_path =} 
                             \KeywordTok{guided_tour}\NormalTok{(}\KeywordTok{holes}\NormalTok{(), }\DataTypeTok{d =} \DecValTok{2}\NormalTok{, }
                                         \DataTypeTok{search_f =}\NormalTok{ tourr}\OperatorTok{:::}\NormalTok{search_geodesic),}
                           \DataTypeTok{rescale =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{verbose =} \OtherTok{TRUE}\NormalTok{)}

\NormalTok{last_basis <-}\StringTok{ }\NormalTok{holes_2d_geo }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(info }\OperatorTok{==}\StringTok{ "interpolation"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{tail}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{pull}\NormalTok{(basis) }\OperatorTok{%>%}\StringTok{ }\NormalTok{.[[}\DecValTok{1}\NormalTok{]]}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123456}\NormalTok{)}
\NormalTok{holes_2d_geo_polish <-}\StringTok{ }\KeywordTok{animate_xy}\NormalTok{(data_mult[,}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{, }\DecValTok{7}\OperatorTok{:}\DecValTok{10}\NormalTok{)], }\DataTypeTok{tour_path =} 
                                    \KeywordTok{guided_tour}\NormalTok{(}\KeywordTok{holes}\NormalTok{(), }\DataTypeTok{d =} \DecValTok{2}\NormalTok{, }
                                                \DataTypeTok{search_f =}\NormalTok{ tourr}\OperatorTok{:::}\NormalTok{search_polish),}
                                  \DataTypeTok{rescale =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{verbose =} \OtherTok{TRUE}\NormalTok{, }
                                  \DataTypeTok{start =}\NormalTok{ last_basis)}
\end{Highlighting}
\end{Shaded}

A slight variation of the plot definition due to the addition of
polishing points is as follows:

\begin{itemize}
\tightlist
\item
  Layer 1: point geom

  \begin{itemize}
  \tightlist
  \item
    data: filter the observations with \(S = \text{interpolation}\);
    bind the global object from optimisation and interpolation and form
    polishing; mutate \(t\) to be the row number of the binded tibble.
  \item
    x: \(t\) is mapped to the x-axis
  \item
    y: \(I\) is mapped to the y-axis
  \item
    colour: \(V\) is mapped to the colour aesthetic
  \end{itemize}
\item
  Layer 2: line geom
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Again using the same data, we are interested to compare the effect of
different \texttt{max.tries} in the 2D projection setting.
\texttt{max.tries} is a hyperparameter that controls the maximum number
of try before the search ends. The default value of 25 is suitable for
1D projection while we suspect it may not be a good option for the 2D
case and hence want to compare it with an alternative, 500. As shown in
Figure \ref{trace-compare}, both trials attain the same index value
after polishing while the small \texttt{max.tries} of 25 is not
sufficient for \texttt{search\_better} to find its global maximum and we
will need to adjust the \texttt{max.tries} argument for the search to
sufficiently explore the parameter space.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/polish-1.pdf}
\caption{\label{trace-compare}Breakdown of index value when using
different max.tries in search better in conjunction with search polish.
Both attain the same final index value after the polishing while using a
\texttt{max.tries} of 25 is not sufficient to find the true maximum.}
\end{figure}

\hypertarget{a-more-complex-example-choosing-the-initial-value-for-polishing-parameter}{%
\subsection{A more complex example: Choosing the initial value for
polishing
parameter}\label{a-more-complex-example-choosing-the-initial-value-for-polishing-parameter}}

\emph{Example: initial value for polishing alpha}
\texttt{search\_polish} is a brute-force algorithm that evaluate 1000
points in the neighbourhood at each loop. Setting an appropriate initial
value for polish\_alpha would avoid wasting search on large vector space
that are not likely to produce higher index value. The default initial
value for polishing step is 0.5 and we are interested in whether this is
an appropriate initial value to use after \texttt{search\_geodesic}. The
problem is a 1D projection of the small dataset using
\texttt{search\_geodesic} and followed by \texttt{search\_polish}. The
top-left panel of Figure \ref{polish-alpha} displays all the projection
bases on the first two principal components, coloured by the
\texttt{polish\_alpha}. We can observe that rather than concentrating on
the ending basis from \texttt{search\_geodesic} as what polishing step
is designed, \texttt{search\_polish} searches a much larger vector
space, which is unnecessary. Thus a customised smaller initial value for
\texttt{polish\_alpha} would be ideal. One way to do this is to
initialised \texttt{polish\_alpha} as the projection distance between
the last two target bases. The top-right panel of Figure
\ref{polish-alpha} shows a more desirable concentrated searching space
near the ending basis. Both specifications of initial value allow the
searches to reach the same ending index values.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/polish-alpha-1.pdf}
\caption{\label{polish-alpha}PCA plot of two different polish alpha
initialisations. A default polish alpha = 0.5 searches a larger space
that is unncessary while a small customised initial value of polish
alpha will search near the ending basis. Both intialisations reach the
same ending index values.}
\end{figure}

While explore the reduced space is an initial attempt to understand the
searching space, there are existing technology for rotating a higher
dimensional space for visualisation. Geozoo is an option. It generates
random points on the high dimensional space and we can overlay it with
the points on the optimisation path to visualise the spread of it on the
high-D sphere.

{[}add example from geozoo{]}

\hypertarget{a-comprehensive-example-of-diagnosing-a-noisy-index-function}{%
\subsection{A comprehensive example of diagnosing a noisy index
function}\label{a-comprehensive-example-of-diagnosing-a-noisy-index-function}}

The interpolation path of holes index, as seen in Figure
\ref{interruption}, is smooth, while this may not be the case for more
complicated index functions. \texttt{kol\_cdf} index, an 1D projection
index function based on Kolmogorov test, compares the difference between
the 1D projected data, \(\mathbf{P}_{n \times 1}\) and a randomly
generated normal distribution, \(y_n\) based on the empirical cumulated
distribution function (ECDF). Denotes the ECDF function as \(F(u)\) with
subscript indicating the variable, the Kolmogorov statistics defined by

\[\max \left[F_{\mathbf{P}}(u) - F_{y}(u)\right]\]

can be seen as a function of the projection matrix
\(\mathbf{A}_{p \times 1}\) and hence a valid index function.

\hypertarget{explore-index-value}{%
\subsubsection{Explore index value}\label{explore-index-value}}

Figure \ref{kol-cdf} compares the tracing plot of the interpolating
points when using different optimisation algorithms:
\texttt{search\_geodesic} and \texttt{search\_better}. One can observe
that

\begin{itemize}
\tightlist
\item
  The index value of \texttt{kol\_cdf} index is much smaller than that
  of holes index
\item
  The link of index values from interpolation bases are no longer smooth
\item
  Both algorithms reach a similar final index value after polishing
\end{itemize}

Polishing step has done much more work to find the final index value in
\texttt{search\_geodesic} than \texttt{search\_better} and this
indicates \texttt{kol\_cdf} function favours of a random search method
than ascent method.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/kol-cdf-1.pdf}
\caption{\label{kol-cdf}Comparison of two different searching methods:
search\_geodesic and search\_better on 1D projection problem for a
noisier index: kol\_cdf. The geodesic search rely heavily on the
polishing step to find the final index value while search better works
well.}
\end{figure}

Now we enlarge the dataset to include two informative variables:
\texttt{x2} and \texttt{x3} and remain 1D projection. In this case, two
local maxima appear with projection matrix being \([0, 1, 0, 0, 0, 0]\)
and \([0, 0, 1 ,0, 0, 0]\).

Using different seeds in \texttt{search\_better} allows us to find both
local maxima d as in Figure \ref{1d-2var-different-seeds}. Comparing the
maximum of both, we can see that the global maximum happens when
\texttt{x2} is found. It is natural to ask then if there is an algorithm
that can find the global maximum without trying on different seeds?
\texttt{search\_better\_random} manages to do it via a
Metropolis-hasting random search as shown in Figure
\ref{1d-2var-better-random}, although at a higher cost of number of
points to evaluate.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/1d-2var-different-seeds-1.pdf}
\caption{\label{1d-2var-different-seeds}The trace plot search better in
a 1D projection problem with two informative variables using different
seeds (without polishing). Since there are two informative variables,
setting different value for seed will lead search better to find either
of the local maximum.}
\end{figure}

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/1d-2var-better-random-1.pdf}
\caption{\label{1d-2var-better-random}Using search better random for the
problem above will result in finding the global maximum but much larger
number of iteration is needed.}
\end{figure}

\hypertarget{explore-searching-space-1}{%
\subsubsection{Explore searching
space}\label{explore-searching-space-1}}

We can also plot the searching points of all three algorithms in the
searching space and explore their relative position against each other
using principal components. As shown in Figure
\ref{1d-2var-explore-proj-pca}, the bases from better1 and better2 only
search a proportion of the searching space while better\_random produces
a more exhaustive search. The large overlapping of better1 and
better\_random is explained by the fact that both algorithms find x2 in
the end.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/1d-2var-explore-proj-pca-1.pdf}
\caption{\label{1d-2var-explore-proj-pca} The projected projection basis
using principal components. The bases from better1 and better2 only
search a proportion of the searching space while better\_random produces
a more exhausive search. The large overlapping of better1 and
better\_random is explained by the fact that both algorithms finds x2 in
the end.}
\end{figure}

\hypertarget{implementation}{%
\section{Implementation: Ferrn package}\label{implementation}}

Everything is coded up in a package. Package structure

When the optimisation ends, the global object will be stored and printed
(it can be turned off by supplying argument \texttt{print\ =\ FALSE}).
Additional messages during the optimisation can be displayed by argument
\texttt{verbose\ =\ TRUE}. Notice that the tibble object allows the
list-column \texttt{basis} to be printed out nicely with the dimension
of the projection basis readily available.

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

\clearpage

\bibliographystyle{agsm}
\bibliography{biblio.bib}

\end{document}
