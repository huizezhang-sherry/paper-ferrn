% !TeX program = pdfLaTeX
\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{graphicx,psfrag,epsf}
\usepackage{enumerate}
\usepackage{natbib}
\usepackage{textcomp}
\usepackage[hyphens]{url} % not crucial - just used below for the URL
\usepackage{hyperref}
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

%\pdfminorversion=4
% NOTE: To produce blinded version, replace "0" with "1" below.
\newcommand{\blind}{0}

% DON'T change margins - should be 1 inch all around.
\addtolength{\oddsidemargin}{-.5in}%
\addtolength{\evensidemargin}{-.5in}%
\addtolength{\textwidth}{1in}%
\addtolength{\textheight}{1.3in}%
\addtolength{\topmargin}{-.8in}%

%% load any required packages here
\usepackage{amssymb, amsmath, mathtools, dsfont} \usepackage[ruled,vlined, linesnumbered]{algorithm2e}

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}



\begin{document}


\def\spacingset#1{\renewcommand{\baselinestretch}%
{#1}\small\normalsize} \spacingset{1}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\if0\blind
{
  \title{\bf Title here}

  \author{
        Author 1 \thanks{The authors gratefully acknowledge \ldots{}} \\
    Department of YYY, University of XXX\\
     and \\     Author 2 \\
    Department of ZZZ, University of WWW\\
      }
  \maketitle
} \fi

\if1\blind
{
  \bigskip
  \bigskip
  \bigskip
  \begin{center}
    {\LARGE\bf Title here}
  \end{center}
  \medskip
} \fi

\bigskip
\begin{abstract}
Friedman \& Tukey commented on their intial paper on projection pursuit
in 1974 that ``the technique use for maximising the projection index
strongly influences both the statistical and the computational aspects
of the procedure.'' While many projection pursuit indices have been
proposed in the literature, few concerns the optimisation procedure. In
this paper, we developed a system of diagnostics aiming to visually
learn how the optimisation procedures find its way towards the optimum.
This diagnostic system can be applied to more general to help
practitioner to unveil the black-box in randomised iteartive
(optimisation) algorithms. An R package, ferrn, has been created to
implement this diagnostic system.
\end{abstract}

\noindent%
{\it Keywords:} optimisation, projection pursuit, guided tourr, visual, diagnostics, R
\vfill

\newpage
\spacingset{1.45} % DON'T change the spacing!

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

In an optimization problem the goal is to find the best solution within
the space of all feasible solutions which typically is represented by a
set of constraints. The problem consists on optimizing an objective
function \(f: S \rightarrow \Re\) with \(S \in \Re^n\) in a reduced
spaced given by the problem constraints to either minimize or maximize a
function\ldots{}. Gradient based optimization has been typically used to
solve such problems. However, there are many situations where
derivatives of an objective function are unavailable or unreliable and
therefore traditional methods based on derivatives are not the best
option to solve an optimization problem.

Derivative free methods provides another option to optimise the
objective function without evaluating any gradient or Hessian
information and a particular class of methods: direct search, has gained
its popularity through its conceptual simplicity. However, the whole
searching process in the algorithm remains a black-box. Plots are
usually used to evaluate and compare the performance of different
algorithms but it can easily become tedious because the code will have
to be modified significantly when comparing different parameters in the
algorithms. For example, a categorical variable with 5 levels can be
easily mapped onto color while mapping another categorical variable with
30 levels will not make the plot informative. Thus the plot needs to be
re-designed to better suits the characteristics of the parameter
(whether the parameter is a scalar or a matrix? whether the parameter is
quantitative or categorical? If categorical, how many levels does the
parameter have?). This motivates the design of a visual diagnostic
framework for optimisation algorithms based on the idea of a
\emph{global object}.

The paper is organised as follows. Section \ref{DFO} gives a general
literature review of optimisation, specifically derivative free
optimisation. Section \ref{vis-diag} presents the new idea of
constructing a systematic visual framework that diagnoses the components
of an optimisation procedure (parameters, searching path, etc). The rest
of the paper serves as a comprehensive example of using the visual
diagnostics on one particular problem: \emph{projection pursuit guided
tour}. Some background knowledge of projection pursuit guided tour is
provided in Section \ref{tour}. Section \ref{apply} applies the concepts
proposed in section \ref{vis-diag} in the tour problem and sets up the
data. The last section, Section \ref{plots}, presents the visual
diagnostic plots and explains how they can help to understand different
aspects of the optimisation in tour.

\hypertarget{DFO}{%
\section{Derivative free optimisation}\label{DFO}}

Given an objective function \(f\), one way of optimising it is to equate
its gradient to zero. In modern optimisation problems, gradient
information can be hard to evaluate or sometimes even impossible and
Derivative-Free Optimisation (DFO) methods can be useful to approach
these problems. One common class of methods in DFO is
\emph{Direct-search methods}. Coined by \citet{hooke1961direct}, direct
search methods don't require any gradient or Hessian information and has
gained its popularity through its simplicity in use and reliability in
solving complicated practical problems. Depends on whether a random
sample is used in the search, this class of methods can be further
classified as \emph{stochastic} or \emph{deterministic}. The stochastic
version of the direct-search methods will be the main optimisation
procedure analysed in this paper.

{[}How about adding more details into derivative free methods? ppp{]}

\hypertarget{difficulties}{%
\subsection{Difficulties}\label{difficulties}}

{[}Are we using projection pursuit/guided tour to better understand the
convergence of optimization algorithms visually in combination with the
algorithms discussed below? Or we are focusing on the optimisation
problem only within the project pursuit context? Some of the problems
listed below are also applicable to optimization problem in general too.
ppp{]}

Below listed several issues in projection pursuit optimisation. Some are
general optimisation problems, while others are more specific for PP
optimisation.

\begin{itemize}
\item
  \emph{Finding global maximum}: Although finding local maximum is
  relatively easy with developed algorithms, it is generally hard to
  guarantee global maximum in a problem where the objective function is
  complex or the number of decision variables is large. Also, there are
  discussions on how to avoid getting trapped in a local optimal in the
  literature.
\item
  \emph{optimising non-smooth function}: When the objective function is
  non-differentiable, derivative information can not be obtained, which
  means traditional gradient- or Hessian- based methods are not
  feasible. Stochastic optimisation method could be an alternative to
  solve these problems.
\item
  \emph{computation speed}: The optimisation procedure needs to be fast
  to compute since tours produces real-time animation of the projected
  data.
\item
  \emph{consistency result in stochastic optimisation}: In stochastic
  algorithm, researchers usually set a seed to ensure the algorithm
  producing the same result for every run. This practice supports
  reproducibility, while less efforts has been made to guarantee
  different seeds will provide the same result.
\item
  \emph{high-dimensional decision variable}: In projection pursuit, the
  decision variable includes all the entries in the projection matrix,
  which is high-dimensional. Researcher would be better off if they can
  understand the relative position of different projection matrix in the
  high-dimensional space.
\item
  \emph{role of interpolation in PP optimisation}: An optimisation
  procedure usually involves iteratively finding projection bases that
  maximises the index function, while tour requires geodesic
  interpolation between these bases to produce a continuous view for the
  users. It would be interesting to see if the interpolated bases could,
  in reverse, help the optimisation reach faster convergence.
\end{itemize}

\emph{Think about how does your package help people to understand
optimisation}

\begin{itemize}
\tightlist
\item
  diagnostic on stochastic optim
\item
  vis the progression of multi-parameter decision variable
\item
  understanding learning rate - neighbourhood parameter
\item
  understand where the local \& global maximum is found - trace plot -
  see if noisy function
\end{itemize}

\hypertarget{tour}{%
\section{Projection pursuit guided tour}\label{tour}}

From Section \ref{tour}, we presents a comprehensive case study on how
to use the visual diagnostics to explore the optimisation in a specific
problem: projection pursuit guided tour. Section \ref{tour} aims to
provide non-experts with an overview of the problem content and the
existing optimisation procedures used in projection pursuit guided tour.
For those who are already familiar with the techniques, feel free to
skip this section.

The optimisation problem we're interested in is in the context of
projection pursuit. Coined by \citet{friedman1974projection}, projection
pursuit is a method that detects the interesting structure
(i.e.~clustering, outliers and skewness) of multivariate data via
projecting it in lower dimensions. Let \(\mathbf{X}_{n \times p}\) be a
data matrix, an n-d projection can be seen as a linear transformation
\(T: \mathbb{R}^p \mapsto \mathbb{R}^d\) defined by
\(\mathbf{P} = \mathbf{X} \cdot \mathbf{A}\), where
\(\mathbf{P}_{n \times d}\) is the projected data and
\(\mathbf{A}_{p\times d}\) is the projection basis. Define
\(f: \mathbb{R}^{p \times d} \mapsto \mathbb{R}\) be an index function
that maps the projection basis \(\mathbf{A}\) onto a scalar value \(I\),
this function is commonly known as the projection pursuit index (PPI)
function, or the index function and can be used to measure the
``interestingness'' of the projection. A number of indice functions have
been proposed in the literature including Legendre index
\citep{friedman1974projection}, hermite index
\citep{hall1989polynomial}, natural hermite index
\citep{cook1993projection}, chi-square index
\citep{posse1995projection}, LDA index \citep{lee2005projection} and PDA
index \citep{lee2010projection}.

As \citet{friedman1974projection} noted ``\ldots{}, the technique use
for maximising the projection index strongly influences both the
statistical and the computational aspects of the procedure.'' A suitable
optimisation procedure is needed to find the projection angle that
maximises the PPI and the quality of the optimisation largely affect the
interesting projections one could possibly observe.

Projection pursuit is usually used in conjunction with a tour method
called \emph{guided tour}. Tour explores the multivariate data
\emph{interactively} via playing a series of projections, that form a
\emph{tour path} and guided tour uses the path that is geodesically the
shortest. Details of the mathematical construction of a tour path can be
found in \citet{buja2005computational}. Guided tour, along with other
types of tour, has been implemented in the \emph{tourr} package in R,
available on the Comprehensive R Archive Network at
\url{https://cran.r-project.org/web/packages/tourr/}
\citep{wickham2011tourrpackage}.

\hypertarget{notation}{%
\subsection{Notation}\label{notation}}

For a projection basis, let the three-subscript notation
\[\mathbf{A}_{jlk}\] represent the projection matrix in iteration \(j\)
with either a searching index \(l\) or an interpolation index \(k\). The
placeholder \(*\) will be the substitue for the non-applicable index. To
give two examples, \(\mathbf{A}_{12*}\) denotes the second searching
basis in the first iteration; \(\mathbf{A}_{1*2}\) denotes the second
interpolation basis in the first iteration.

If we are being pedantic, all the target bases, except the starting
basis, should have a searching index since it is the last candidate
basis that successfully allows the optimisation algorithm to end and
output a new basis for interpolation. If we denotes the length of each
search (number of basis searched in each iteration) as
\(l_1, l_2, \cdots, l_J\) and the length of each interpolation is
\(k_1, k_2, \cdots, k_J\) , then the searching index for target basis in
each iteration will become
\(\mathbf{A}_{1l_1*}, \mathbf{A}_{2l_2*}, \cdots, \mathbf{A}_{Jl_J*}\).
We simplify this notation for target bases by using a superscript as
\[\mathbf{A}^{0}, \mathbf{A}^{1}, \mathbf{A}^{2}, \cdots, \mathbf{A}^{J}\]
where \(\mathbf{A}^{0}\) is the starting basis. Notice that in the case
when the complex notation can't be avoided, we shall separate each index
using a comma and write the index in brackets if necessary. Using the
notation above, all the bases on the interpolation path (including
target and interpolation bases) can be written as in Equation
\ref{eq:interp-path}.

\begin{equation}
\{ 
\mathbf{A}^0, 
\mathbf{A}^1, 
\mathbf{A}_{1 \ast 1}, 
\mathbf{A}_{1 \ast 2},
\cdots, 
\mathbf{A}^2, 
\mathbf{A}_{2 \ast 1}, 
\mathbf{A}_{2 \ast 2}, 
\cdots, 
\mathbf{A}^J,
\mathbf{A}_{J \ast 1}, 
\mathbf{A}_{J \ast 2}, 
\cdots, 
\mathbf{A}_{J \ast K},
\}
\label{eq:interp-path}
\end{equation}

where \(K\) denotes the last interpolating index. A visual
representation of the interpolation path ( for iteration one) modified
from \citet{buja2005computational} is shown in Figure \ref{tour-path}.
If we use a dot to represent a plane in the searching space, the
searching points along with the current and target basis in iteration
one can sketched in Figure \ref{searching-points}. Combine the two
above, we can write all the bases in the first iteration (including the
starting basis) in its natural ordering as in Equation \ref{eq:vectorA}.

\begin{equation}
\{
\mathbf{A}^{0}, 
\mathbf{A}_{1 1\ast}, 
\mathbf{A}_{1 2\ast}, 
\cdots, 
\mathbf{A}^{1},
\mathbf{A}_{1\ast 1}, 
\mathbf{A}_{1\ast 2},  
\cdots, 
\mathbf{A}_{1\ast k_1}
\}
\label{eq:vectorA}
\end{equation}

\begin{figure}
\includegraphics[width=1\linewidth,height=0.6\textheight]{/Users/hzha400/Documents/3.PhD/paper-tour-vis/figures/tour_path_increasing} \caption{\label{tour-path}An illustration of the tour path}\label{fig:tour-path}
\end{figure}

\begin{figure}
\includegraphics[width=1\linewidth,height=0.6\textheight]{/Users/hzha400/Documents/3.PhD/paper-tour-vis/figures/tour_path_increasing} \caption{\label{searching-points}An illustration of the tour path}\label{fig:searching-points}
\end{figure}

\hypertarget{optimisation-problem-and-existing-algorithms}{%
\subsection{Optimisation problem and existing
algorithms}\label{optimisation-problem-and-existing-algorithms}}

Now we begin to formulate the optimisation problem. Given a randomly
generated starting basis \(\mathbf{A}^0\), projection pursuit finds the
final projection basis
\(\mathbf{A}^J = [\mathbf{a}_1, \cdots, \mathbf{a}_d]\), where
\(\mathbf{a}_i\) is a \(p \times 1\) vector, satisfies the following
optimisation problem:

\begin{align}
&\arg \max_{\mathbf{A} \in \mathcal{A}} f(\mathbf{A}) \\
s.t. & \mathcal{A} = \{ \forall \mathbf{a}_i, \mathbf{a}_j \in \mathbf{A}: \lVert \mathbf{a}_i \rVert = 1 \text{ and } \mathbf{a}_i \mathbf{a}_j = 0 \}
\end{align}

via an iterative search of target basis:
\(\{\mathbf{A}^0, \mathbf{A}^1, \mathbf{A}^2, \cdots \cdots \mathbf{A}^J\}\).

There are three existing methods for optimisating PPI function and we
review them below.

\citet{posse1995projection} proposed a stochastic direct search method,
a random search algorithm. Given a current basis \(\mathbf{A}^{j-1}\), a
candidate basis \(\mathbf{A}_{jl*}\) is sampled in the neighbourhood
defined by the radius of the p-dimensional sphere, \(\alpha\) of the
current basis \(\mathbf{A}^{j}\) by
\(\mathbf{A}_{jl*} = \mathbf{A}^{j-1} + \alpha \mathbf{A}_{rand}\). If
the candidate basis has a higher index value than the current basis, it
is outputed as the target basis \(\mathbf{A}^{j}\) along with other
metadata and the current iteration stops. If no basis is found to have
higher index value after the maximum number of tries \(l_{\max}\), the
algorithm stops with nothing outputted. \(c\) is the halfing parameter
and when \(c > 30\), the nieghbourhood parameter \(\alpha\) in the next
iteration will be reduced by half. The algorithm for a random search is
summarised in Algorithm \ref{random-search}.

\begin{algorithm}
\SetAlgoLined
  \SetKwInOut{Input}{input}
  \SetKwInOut{Output}{output}
    \Input{The current projection basis: $\mathbf{A}^{j-1}$; The index function: $f$}
    \Output{The global object; The target basis: $\mathbf{A}^{j}$}
  initialisation\;
  \While{$l < l_{\max}$}{
    Generate $\mathbf{A}_{jl*} = \mathbf{A}^{j-1} + \alpha \mathbf{A}_{\text{rand}}$ ensuring $\mathbf{A}_{j, l,*}$ is orthonormal\;
    Compute $I_{jl*}  = f(\mathbf{A}_{jl*})$\;
    \eIf{$I_{jl*} > I^{j-1}$}{
      $A^{j} = A_{jl*}$, $I^{j} = I_{jl*}$\;
      }{
      $c = c + 1$\;
      }
    $l = l + 1$\;
  }
  \caption{random search}
  \label{random-search}
\end{algorithm}

\citet{cook1995grand} explained the use of a gradient ascent
optimisation with the assumption that the index function is continuous
and differentiable. Since some indices could be non-differentiable, the
computation of derivative is replaced by a pseudo-derivative of
evaluating five randomly generated directions in a tiny nearby
neighbourhood. Taking a step on the straight derivative direction has
been modified to maximise the projection pursuit index along the
geodesic direction. See Algorithm \ref{search-geodesic} for a
summarisation of the steps.

\begin{algorithm}
\SetAlgoLined
\SetKwInOut{Input}{input}
  \SetKwInOut{Output}{output}
    \Input{The current projection basis: $\mathbf{A}^{j-1}$; The index function: $f$}
    \Output{The global object; The target basis: $\mathbf{A}^{j}$}
  initialisation\;
  \While{$l < l_{\max}$}{
    Generate ten bases in five random directions: $\mathbf{A}_{jl*}: \mathbf{A}_{j,(l + 9), *}$ within a small neighbourhood $\text{dist}$\;
    Find the direction with the largest index value: $\mathbf{A}_{j, l_{d}, *}$\;
    Construct the geodesic from $\mathbf{A}^{j-1}$ to $\mathbf{A}_{j, l_{d}, *}$\;
    Find $\mathbf{A}_{j,l_g, *}$ on the geodesic that has the largest index value \;
    Compute $I_{j,l_g, *} = f(\mathbf{A}_{j,l_g, *})$, $p_{\text{diff}} = (I_{j,l_g, *} - I^{j-1})/I_{j,l_g, *}$\;
      \If{$p_{\text{diff}} > 0.001$}{
        $A^{j} = A_{j,l_g, *}$, $I^{j} = I_{j,l_g, *}$\;
      }
    $l = l + 1$\;
  }
  \caption{search geodesic}
  \label{search-geodesic}
\end{algorithm}

Simulated annealing
\citep[\citet{kirkpatrick1983optimization}]{bertsimas1993simulated} is a
non-derivative procedure based on a non-increasing cooling scheme
\(T(l)\). Given an initial \(T_0\), the temperature at iteration \(l\)
is defined as \(T(l) = \frac{T_0}{log(l + 1)}\). The simulated annealing
algorithm works as follows. Given a neighbourhood parameter \(\alpha\)
and a randomly generated orthonormal basis \(A_{rand}\), a candidate
basis is constructed as
\(\mathbf{A}_{jl*} = (1 - \alpha)\mathbf{A}^{j} + \alpha \mathbf{A}_{rand}\).
If the index value of the candidate basis is larger than the one of the
current basis, the candidate basis becomes the target basis. If it is
smaller, the candidate is accepted with probability
\(P= \min\left\{\exp\left[\frac{I^{j-1} - I_{jl*}}{T(l)}\right],1\right\}\)
where \(I^{j-1}\) and \(I_{jl*}\) are the index value of the current and
candidate basis respectively. The algorithm can be summarised as in
Algorithm \ref{simulated_annealing}.

\begin{algorithm}
\SetAlgoLined
\SetKwInOut{Input}{input}
  \SetKwInOut{Output}{output}
    \Input{The current projection basis: $\mathbf{A}^{j-1}$; The index function: $f$}
    \Output{The global object; The target basis: $\mathbf{A}^{j}$}
  initialisation\;
  \While{$l < l_{\max}$}{
    Generate $\mathbf{A}_{jl*} = (1 - \alpha)\mathbf{A}^{j-1} + \alpha \mathbf{A}_{rand}$ ensuring $\mathbf{A}_{jl*}$ is orthonormal \;
    Commpute $I_{jl*} = f(\mathbf{A}_{jl*})$ and $T(l) = \frac{T_0}{\log(l + 1)}$\;
      \eIf{$I_{jl*} > I^{j-1}$}{
        $A^{j} = A_{jl*}$, $I^{j} = I_{jl*}$\;
      }{
        Compute $P= \min\left\{\exp\left[\frac{I^{j-1} - I_{jl*}}{T(l)}\right],1\right\}$\;
        Draw $D$ from a uniform distribution: $D \sim \text{Unif(0, 1)}$\;
        \If{$P > D$}{
          $A^{j} = A_{jl*}$, $I^{j} = I_{jl*}$\;
        }
      }
    $l = l + 1$\;
  }
  \caption{simulated annealing}
  \label{simulated_annealing}
\end{algorithm}

Below listed several features characterise the optimisation procedures
needed in projection pursuit

\begin{itemize}
\item
  \emph{Being able to handle non-differentiable PPI function}: The PPI
  function could be non-differentiable, thus derivative free methods are
  preferred.
\item
  \emph{Being able to optimise with constraints}: The constraint comes
  from projection matrix being an orthonormal matrix.
\item
  \emph{Being able to find both local and global maximum}: Although the
  primary interest is to find the global maximum, local maximum could
  also reveal structures in the data that are of our interest.
\end{itemize}

\hypertarget{vis-diag}{%
\section{Visual diagnostic system}\label{vis-diag}}

{[}I would expand this section more as the core contribution. ppp{]}

\hypertarget{motivation}{%
\subsection{Motivation}\label{motivation}}

Random search methods has a black-box mechanism and focuses solely on
finding the global maximum point, while the projection pursuit problem
we have aims at \emph{exploring} the data and thus is interested in how
the algorithm finds its maximum. This motivates us \textbf{to develop a
visual diagnostic system for exploring the optimisation searching path}.

The necessity of developing such a system rather than simply producing
different diagnostic plots is because the diagnostics of each variable
requires a different function and these functions can't be scaled to
other problems. Thus we want to establish a set of rules that can
generalise the diagnostic of iterative algorithms.

The idea of generalising all the diagnostic plots under one framework is
inspired by the concept of \emph{grammar of
graphic}\citep{wickham2010layered}, which powers the primary graphical
system in R, ggplot2 \citep{ggplot2}. In grammar of graphic, plots are
not defined by its appearance (i.e.~boxplot, histogram, scatter plot
etc) but by ``stacked layers''. By this design, ggplot doesn't need to
develop a gazillion of functions that each produces a different type of
plot. Instead, it aesthetically maps the variables to the geometric
objects and builds the plot through different layers.

\hypertarget{global-object}{%
\subsection{Global object}\label{global-object}}

Ggplot requires a data frame that contains all the variables to plot and
a \emph{global object} is constructed as the data frame supplied to the
visual diagnostic plots to better suit the characters of iterative
optimisation algorithms. Given an optimisation algorithm, two primary
variables of interest are the \emph{decision variable: \(\mathbf{A}\)}
and the \emph{value of the objective function: \(I\)}. To further
simplify the notation for \(\mathbf{A}\), we write the bases as a column
vector denoting by a single subscript by their natural ordering as in
Equation \ref{vector-basis}.

\begin{equation}
\{
\mathbf{A}_0, 
\mathbf{A}_1, 
\mathbf{A}_2, 
\cdots,
\mathbf{A}_T
\label{vector-basis}
\}
\end{equation}

where \(T\) is the total number of plane serached by the optimisation
algorithm including all the target planes, all the interpolating planes
and all the candidate planes but NOT the starting plane.

\emph{Iterators} indexes the data collected and has a time series
feature that prescribes the its natural ordering of the decision varible
in the searching. The simpliest iterator, \emph{index per observation:
\(t\)}, is a unique identifier for each observation in the data. For
each level of iteration, we design two types of indices: \emph{index per
iteration: \(j\)} is fixed for each observations in one iteration and
has an increment of one once a new iteration starts. \emph{index within
iteration: \(l\)} has an increment of one for each observation in an
iteartion and starts over from one once a new iteration starts. A sketch
of the difference between these three iterators is provided in Figure
\ref{iterators}. In projection pursuit optimisation algorithms, there is
one level of iteartion and hence exists three iterators: \texttt{id}
indices each observation by a unique number; \texttt{tries} is the index
per iteration iterator that gets updated once a search-and-interpolate
step is finished; and \texttt{loop} is the index within iteration
iterator and starts over from one at the beginning of a new
\texttt{tries}. We give the interpolating basis a different index \(k\)
for projection pursuit guided tour. It is similar in nature to \(l\) but
is specific for interpolating bases, which is usually not part of the
optimisation.

\begin{figure}
\includegraphics[width=1\linewidth,height=0.25\textheight]{/Users/hzha400/Documents/3.PhD/paper-tour-vis/figures/iterators} \caption{\label{iterators} A sketch of the design of iterators in iterative algorithms.}\label{fig:iterators}
\end{figure}

There could exist other parameters that are also of our interest but
can't be classified as one of the three categories. They are defined
under the fourth category: \emph{other parameter of interest: \(S\)}. In
projection pursuit, three other parameters of our interest includes
\texttt{method}, \texttt{alpha} and \texttt{info}. \texttt{method}
identifies the name of the searching method used and we are interested
in comparing the performance between different algorithms under direct
search. The neighbourhood parameter \texttt{alpha} controls the size of
the sampling space and we are interested to understand how the searching
space shrinks as the algorithm progresses. \texttt{info} labels
different stages in the searching process. A sketch of the global object
for projection pursuit guided tour is presented in Figure
\ref{fig:glb-obj}. The full data structure can thus be shown as in
Equation \ref{eq:data-structure}.

\begin{equation}
\left[
\begin{array}{c|cc|ccc|ccc}
t & \mathbf{A} & I & j &  l  & k & S_{1}& \cdots & S_{p}\\
\hline
1 & \mathbf{A}_0 & I_0 & 0 & \ast & \ast & \ast & \cdots & \ast\\
\hline
2 & \mathbf{A}_1 & I_1 & 1 & 1 & \ast & S_{1, 1} & \cdots & S_{1, p}\\
3 & \mathbf{A}_2 & I_2 & 1 & 2 & \ast & S_{2, 1} & \cdots & S_{2, p}\\
\vdots & \vdots &\vdots & \vdots &\vdots & \vdots &\vdots &\cdots &\vdots\\
\vdots & \vdots & \vdots & 1 & l_1 & \ast & \vdots &  \cdots & \vdots\\
\hline
\vdots &\vdots & \vdots & 1 & \ast & 1& \vdots &  \cdots & \vdots\\
\vdots &\vdots &\vdots& 1 & \ast & 2& \vdots& \cdots & \vdots\\
\vdots &\vdots &\vdots &\vdots  &\vdots & \vdots &\vdots &\cdots &\vdots \\
\vdots &\vdots &\vdots & 1 & \ast & k_1&\vdots & \cdots & \vdots\\
\hline
\vdots &\vdots &\vdots &\vdots  &\vdots & \vdots &\vdots &\cdots &\vdots \\
T+1 & \mathbf{A}_T & I_T & J &  l_J & \ast & S_{T, 1}& \cdots & S_{T, p}\\
\end{array}
\right]
\label{eq:data-structure}
\end{equation}

\begin{figure}
\includegraphics[width=1\linewidth,height=0.2\textheight]{/Users/hzha400/Documents/3.PhD/paper-tour-vis/figures/global_obj} \caption{\label{glb-obj}The global object in projection pursuit guided tour.}\label{fig:glb-obj}
\end{figure}

\hypertarget{simulated-data}{%
\subsection{Simulated data}\label{simulated-data}}

We first simulate some random variables of size 1000 with different
structures. \texttt{x1}, \texttt{x8}, \texttt{x9} and \texttt{x10} are
simulated from normal distribution iwth zero mean and variance of one as
in equation \ref{eq:sim-norm}. When using projection pursuit to explore
the data structure based on its departure from normality, the entry in
the projection basis for these variables should be close to zero in
theory. \texttt{x2} to \texttt{x7} are mixture of normal distribution
with different weights and locations. Equation \ref{eq:sim-x2} to
\ref{eq:sim-x7} show the distribution of each variables and Figure
\ref{origin-data} shows the histogram of each variable except
\texttt{x3}. All the variables are then scaled to ensure the mixture has
variance of one.

\begin{align}
x_1 \overset{d}{=} x_8 \overset{d}{=} x_9 \overset{d}{=} x_{10}& \sim \mathcal{N}(0, 1) \label{eq:sim-norm} \\
x_2 &\sim 0.5 \mathcal{N}(-3, 1) + 0.5 \mathcal{N}(3, 1)\label{eq:sim-x2}\\
\Pr(x_3) &= 
\begin{cases}
0.5 & \text{if $x_3 = -1$ or $1$}\\
0 & \text{otherwise}
\end{cases}\label{eq:sim-x3}\\
x_4 &\sim 0.25 \mathcal{N}(-3, 1) + 0.75 \mathcal{N}(3, 1) \label{eq:sim-x4}\\
x_5 &\sim \frac{1}{3} \mathcal{N}(-5, 1) + \frac{1}{3} \mathcal{N}(0, 1) + \frac{1}{3} \mathcal{N}(5, 1)\label{eq:sim-x5}\\
x_6 &\sim 0.45 \mathcal{N}(-5, 1) + 0.1 \mathcal{N}(0, 1) + 0.45 \mathcal{N}(5, 1)\label{eq:sim-x6}\\
x_7 &\sim 0.5 \mathcal{N}(-5, 1) + 0.5 \mathcal{N}(5, 1) 
\label{eq:sim-x7}
\end{align}

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/origin-data-1.pdf}
\caption{\label{origin-data} The distribution of simulated data except
x3}
\end{figure}

We form our first dataset using variable \texttt{x1}, \texttt{x2},
\texttt{x8}, \texttt{x9} and \texttt{x10} and supply it to one of the
above algorithm, say \texttt{search\_geodesic} in the \texttt{tourr}
package. When the optimisation ends, the global object will be stored
and printed (it can be turned off by supplying argument
\texttt{print\ =\ FALSE}). Additional messages during the optimisation
can be displayed by \texttt{verbose\ =\ TRUE}. Below shows the first
five rows of the global object. The global object meets the definition
of tidy data introduced in \citep{wickham2014tidy} where each
observation forms a row, each variable forms a column and each type of
observational unit forms a table. The adoption of tidy data makes it
easier for data wrangling and visualisation, which powers the visual
diagnostics system introduced in this paper.

\newpage

\begin{verbatim}
## # A tibble: 5 x 8
##   basis             index_val tries info           loop method       alpha    id
##   <list>                <dbl> <dbl> <chr>         <dbl> <chr>        <dbl> <int>
## 1 <dbl[,1] [5 x 1]>     0.749     1 start            NA <NA>           0.5     1
## 2 <dbl[,1] [5 x 1]>     0.730     1 random_search     1 search_bett~   0.5     2
## 3 <dbl[,1] [5 x 1]>     0.743     1 random_search     2 search_bett~   0.5     3
## 4 <dbl[,1] [5 x 1]>     0.736     1 random_search     3 search_bett~   0.5     4
## 5 <dbl[,1] [5 x 1]>     0.747     1 random_search     4 search_bett~   0.5     5
\end{verbatim}

\hypertarget{visual-diagnostics}{%
\section{Visual diagnostics}\label{visual-diagnostics}}

Below we will present several examples of diagnosing different aspects
of the projection pursuit optimisation. We will present:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  static plots to explore the index value,
\item
  animated plots to explore the projection basis and,
\item
  a self-contained example to optimise a complex index function.
\end{enumerate}

In the first two sections, we will first provide a toy example that is
easy to grasp and then more examples that can help us to understand the
algorithm and parameter choice. Remeber the research question we raised
earlier, the purpose of visual diagnostics is to understand:

\begin{itemize}
\item
  Whether the algorithm has successfully found the maximum and how the
  index value changes throughout the algorithm?
\item
  How does the searching space look like, that is, geometrically, where
  are the projection bases located in the space?
\end{itemize}

The first question can be answered using a static plot with x-axis
showing the progression of the optimisation and y-axis showing the value
of the objective function. The second question can be addressed via
visualising the rotating high dimensional space or its projection on the
reduced 2D space. Thus animated visualisation is needed to preceive the
optimisation path in the searching space.

Since the global object is already tidy, not further tidying steps is
needed, while certain data wrangling steps
\citep{wickham2016rfordatascience} are still needed to transform the
global object into desirable format for one particular visualisation. To
emphasize on this good practice of data analysis, we will describe the
transformation steps needed for each diagnostic plots before stepping
into visualisation.

\hypertarget{static}{%
\subsection{Explore the value of objective function}\label{static}}

\hypertarget{searching-points}{%
\subsubsection{Searching points}\label{searching-points}}

A primary interest of diagnosing an optimisation algorithm is to study
how it finds its optimal progressively. We could plot the index value
across its natural ordering, however, different iterations may have
different number of points and, towards the end of the search there
could easily be hundreds of bases being tested before the target basis
is found. In the plot, points from those iterations towards the end will
occupy the vast majority of the plot space. This motivates to use
summarisation. Rather than knowing the index value of \emph{every}
basis, we are more interested to have a general summary of all the index
value in that iteration and more importantly, the basis with the largest
index value (since it prescribes the next geodesic interpolation and
future searches).

Boxplot is a suitable candidate that provides five points summary of the
data, however it has one drawback: it doesn't report the number of point
in each box. We may risk losing information on how many points it takes
to find the target basis by displaying the boxplot alone for all
\texttt{tries}. Thus, the number of point in each iteration is displayed
at the bottom of each box and we provide options to switch iteration
with small number of points to a point geometry, which is achieved via
an \texttt{cutoff} argument. A line geometry is also added to link the
points with the largest index value in each iteration. This helps to
visualise the improvement made in each iteration. Using the concept of
\emph{gramma of graphics} \citep{wickham2010layered}, the plot for
exploring index value can be defined in three layers as:

\begin{itemize}
\tightlist
\item
  Layer 1: boxplot geom

  \begin{itemize}
  \tightlist
  \item
    data: group by \texttt{tries} and filter the observations in the
    group that have count greater than \texttt{cutoff\ =\ 15}.
  \item
    x: \texttt{tries} is mapped to the x-axis
  \item
    y: the index value after statistical transformation
    \(y = \{Q_q(I_{jlk} \cdot \mathds{1} (j = x, k = \ast))\}\) is
    mapped to the y-axis where \(q\) takes one of \(0, 25, 50, 75, 100\)
    and \(Q_q(x)\) finds the qth-quantile for the vector \(x\).
    \(\mathds{1}(.)\) is the identity operator.
  \end{itemize}
\item
  Layer 2: point geom

  \begin{itemize}
  \tightlist
  \item
    data: group by \texttt{tries} and filter the observations in the
    group that have count less than \texttt{cutoff\ =\ 15}.
  \item
    x: \texttt{tries} is mapped to the x-axis
  \item
    y: \texttt{index\_val} is mapped to the y-axis
  \end{itemize}
\item
  Layer 3: line geom

  \begin{itemize}
  \tightlist
  \item
    data: filter the points with the highest index value in each
    \texttt{tries}
  \item
    x: \texttt{tries} is mapped to the x-axis
  \item
    y: \texttt{index\_val} is mapped to the y-axis
  \end{itemize}
\end{itemize}

\hypertarget{toy-example-exploring-searching-points}{%
\paragraph{Toy example: exploring searching
points}\label{toy-example-exploring-searching-points}}

We choose variable \texttt{x1}, \texttt{x2}, \texttt{x3}, \texttt{x8},
\texttt{x9} and \texttt{x10} to perform a 2D projection with tour.
Parameter \texttt{search\_f\ =\ tour::search\_better} and
\texttt{max.tries\ =\ 500} is used. The index value of the searching
points are shown in Figure \ref{points}. Label at the bottom indicates
the number of observations in each iteration and facilitates the choice
of \texttt{cutoff} argument (by default \texttt{cutoff\ =\ 15}). We
learn that the \texttt{search\_better} quickly finds better projection
basis with higher index value at first and the takes longer to find a
better one later.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/points-tries-1.pdf}
\caption{\label{points}A comparison of plotting the same search points
with different plot designs. The left plot doesn't efficiently use the
plot space to convey information from the plot while the right plot
provides good summarisation of data and number of points in each tries.}
\end{figure}

\hypertarget{interpolating-points}{%
\subsubsection{Interpolating points}\label{interpolating-points}}

Sometimes, rather than explore the searching points, we may be
interested in explore the points on the interpolation path (target and
interpolating points) since these points will be played by the tour
animation. Since interpolation paths are geodesically the shortest, a
summarisation using boxplot geometry is no longer needed. The slightly
modified plot definition is shown below:

\begin{itemize}
\tightlist
\item
  Layer 1: point geom

  \begin{itemize}
  \tightlist
  \item
    data: filter the observations with \texttt{info} being
    \texttt{interpolation} and mutate \texttt{id} to be the row number
    of the subsetted tibble
  \item
    x: \texttt{id} is mapped to the x-axis
  \item
    y: \texttt{index\_val} is mapped to the y-axis
  \end{itemize}
\item
  Layer 2: line geom

  \begin{itemize}
  \tightlist
  \item
    using line goemetry for the same data and aesthetics
  \end{itemize}
\end{itemize}

\hypertarget{a-more-complex-example-interruption}{%
\paragraph{A more complex example:
Interruption}\label{a-more-complex-example-interruption}}

We use the same dataset as the toy example above to explore the search
function \texttt{search\_better} and we want to learn how the index
value changes on the interpolation path for \texttt{holes} index. From
the left panel of Figure \ref{interruption}, we observe that when
interpolating from the current basis to the target basis, the index
value may not be monotone: we could reach a basis with higher index
value than the target basis on the interpolation path. In this sense, we
would be better off using the basis with the highest index value on the
interpolation path as the current basis for the next iteration (rather
than using the target basis).

Hence, an interruption is constructed to accept the interpolating bases
only up to the one with the largest index value. After implementing this
interruption, the search finds higher final index value with fewer steps
as shown in the right panel of Figure \ref{interruption}.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/interruption-1.pdf}
\caption{\label{interruption}Trace plots of the interpolated basis with
and without the interruption. The interruption stops the interpolation
when the index value starts to decrease at id = 60. The implementation
of the interuption finds an ending basis with higher index value using
fewer steps.}
\end{figure}

\hypertarget{polishing-points}{%
\subsubsection{Polishing points}\label{polishing-points}}

In principle, all the optimisation routines should result in the same
output for the same problem while this may not be the case in real
application. This motivates the creation of a polishing search that
polishes the final basis found and achieves unity across different
methods.

\texttt{search\_polish} takes the final basis of a given search as a
start and uses a brutal-force approach to sample a large number of basis
(\texttt{n\_sample}) in the neighbourhood. Among those sampled basis,
the one with the largest index value is chosen to be compared with the
current basis. If its index value is larger than that of the current
basis, it becomes the current basis in the next iteration. If no basis
is found to have larger index value, the searching neighbourhood will
shrink and the search continues. The polishing search ends when one of
the four stopping criteria is satisfied:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  the chosen basis can't be too close to the current basis
\item
  the percentage improvement of the index value can't be too small
\item
  the searching neighbourhood can't be too small
\item
  the number of iteration can't exceed the \texttt{max.tries}
\end{enumerate}

The usage of search\_polish is as follows. After the first search, the
final basis from the interpolation is extracted and supplied to the
second search as the \texttt{start} argument. \texttt{search\_polish} is
used as the search function. All the other arguments should remain the
same.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123456}\NormalTok{)}
\NormalTok{holes_2d_geo <-}\StringTok{ }\KeywordTok{animate_xy}\NormalTok{(data_mult[,}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{, }\DecValTok{7}\OperatorTok{:}\DecValTok{10}\NormalTok{)],}\DataTypeTok{tour_path =} 
                             \KeywordTok{guided_tour}\NormalTok{(}\KeywordTok{holes}\NormalTok{(), }\DataTypeTok{d =} \DecValTok{2}\NormalTok{, }
                                         \DataTypeTok{search_f =}\NormalTok{ tourr}\OperatorTok{:::}\NormalTok{search_geodesic),}
                           \DataTypeTok{rescale =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{verbose =} \OtherTok{TRUE}\NormalTok{)}

\NormalTok{last_basis <-}\StringTok{ }\NormalTok{holes_2d_geo }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(info }\OperatorTok{==}\StringTok{ "interpolation"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{tail}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{pull}\NormalTok{(basis) }\OperatorTok{%>%}\StringTok{ }\NormalTok{.[[}\DecValTok{1}\NormalTok{]]}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123456}\NormalTok{)}
\NormalTok{holes_2d_geo_polish <-}\StringTok{ }\KeywordTok{animate_xy}\NormalTok{(data_mult[,}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{, }\DecValTok{7}\OperatorTok{:}\DecValTok{10}\NormalTok{)], }\DataTypeTok{tour_path =} 
                                    \KeywordTok{guided_tour}\NormalTok{(}\KeywordTok{holes}\NormalTok{(), }\DataTypeTok{d =} \DecValTok{2}\NormalTok{, }
                                                \DataTypeTok{search_f =}\NormalTok{ tourr}\OperatorTok{:::}\NormalTok{search_polish),}
                                  \DataTypeTok{rescale =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{verbose =} \OtherTok{TRUE}\NormalTok{, }
                                  \DataTypeTok{start =}\NormalTok{ last_basis)}
\end{Highlighting}
\end{Shaded}

Slight variation of plot definition due to the addition of polishing
points is as follows:

\begin{itemize}
\tightlist
\item
  Layer 1: point geom

  \begin{itemize}
  \tightlist
  \item
    data: filter the observations with \texttt{info} being
    \texttt{interpolation}; bind the global object from optimisation and
    interpolation and form polishing; mutate \texttt{id} to be the row
    number of the binded tibble.
  \item
    x: \texttt{id} is mapped to the x-axis
  \item
    y: \texttt{index\_val} is mapped to the y-axis
  \item
    color: \texttt{method} is mapped to the color aesthetic
  \end{itemize}
\item
  Layer 2: line geom

  \begin{itemize}
  \tightlist
  \item
    using line goemetry for the same data and aesthetics
  \end{itemize}
\end{itemize}

\hypertarget{another-example-polish}{%
\paragraph{Another example: Polish}\label{another-example-polish}}

Again using the same data, we are interested to compare the effect of
different \texttt{max.tries} in the 2D projection setting.
\texttt{max.tries} is a hyperparameter that controls the maximum number
of try before the search ends. The default value of 25 is suitable for
1D projection while we suspect it may not be a good option for the 2D
case and hence want to compare it with an alternative, 500. As shown in
Figure \ref{trace-compare}, both trials attain the same index value
after polishing while the small \texttt{max.tries} of 25 is not
sufficient for \texttt{search\_better} to find its global maximum and we
will need to adjust the \texttt{max.tries} argument for the search to
succiciently explore the parameter space.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/polish-1.pdf}
\caption{\label{trace-compare}Breakdown of index value when using
different max.tries in search better in conjunction with search polish.
Both attain the same final index value after the polishing while using a
max.tries 25 is not sufficient to find the ture maximum.}
\end{figure}

\newpage

\hypertarget{animated}{%
\subsection{Explore searching space}\label{animated}}

In projection pursuit, the projection bases \(\mathbf{A}_{p \times d}\)
are usually of dimension \(p \times d\) and hence can't be visualised in
a 2D plot. An option to explore the searching space of these bases is to
explore a reduced space via principal component analysis (PCA). The
visualisation can thus be defined as

\begin{itemize}
\tightlist
\item
  Layer 1: point geom

  \begin{itemize}
  \tightlist
  \item
    data: subset the basis of interest and arrange into a matrix format;
    perform PCA on the basis matrix and compute the projected basis on
    the first two principal components; bind the variables from the
    original global object and form a tibble
  \item
    x: the projected basis on the first principal component
  \item
    y: the projected basis on the second principal component
  \item
    color: an variable of interest is mapped onto color
  \end{itemize}
\end{itemize}

While explore the reduced space is an initial attempt to understand the
searching space, there are existing technology for rotating a higher
dimensional space for visualisation. Geozoo is an option. It generates
random points on the high dimensional space and we can overlay it with
the points on the optimisation path to visualise the spread of it on the
high-D sphere.

\hypertarget{a-toy-example-understand-different-stage-of-search_geodesic}{%
\subsubsection{A toy example: understand different stage of
search\_geodesic}\label{a-toy-example-understand-different-stage-of-search_geodesic}}

\emph{Example: understand search\_geodesic} {[}feel like this example is
merely explaining search geodesic algorithm, so maybe introduce the
animated plot here? xxx{]} \texttt{search\_geodesic} is a two-stage
ascending algorithm with four different stages in the search and a PCA
plot useful to understand how the algorithm progresses and the relative
position of each basis in the PCA projected 2D space. Starting from the
start basis, a directional search is conducted in a narrow neighbourhood
on five random directions. The best one is picked and a line search is
then run on the geodesic direction to find the target basis. The
starting and target bases are then interpolated. In the next iteration,
the target basis becomes the current basis and then procedures
continues.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/pca-1.pdf}
\caption{\label{pca}PCA plot of search geodesic Coloring by info allows
for better understanding of each stage in the geodesic search}
\end{figure}

\hypertarget{a-more-complex-example-choosing-the-initial-value-for-polishing-parameter}{%
\subsubsection{A more complex example: Choosing the initial value for
polishing
parameter}\label{a-more-complex-example-choosing-the-initial-value-for-polishing-parameter}}

\emph{Example: initial value for polishing alpha}
\texttt{search\_polish} is a brutal-force algorithm that evaluate 1000
points in the neighbourhood at each loop. Setting an appropriate initial
value for polish\_alpha would avoid wasting search on large vector space
that are not likely to produce higher index value. The default initial
value for polishing step is 0.5 and we are interested in whether this is
an appropriate initial value to use after \texttt{search\_geodesic}. The
problem is a 1D projection of the small dataset using
\texttt{search\_geodesic} and followed by \texttt{search\_polish}. The
top-left panel of Figure \ref{polish-alpha} displays all the projection
bases on the first two principal components, colored by the
\texttt{polish\_alpha}. We can observe that rather than concentrating on
the ending basis from \texttt{search\_geodesic} as what polishing step
is designed, \texttt{search\_polish} searches a much larger vector
space, which is unnecessary. Thus a customised smaller initial value for
\texttt{polish\_alpha} would be ideal. One way to do this is to
initialised \texttt{polish\_alpha} as the projection distance between
the last two target bases. The top-right panel of Figure
\ref{polish-alpha} shows a more desirable concentrated searching space
near the ending basis. Both specifications of initial value allow the
searches to reach the same ending index values.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/polish-alpha-1.pdf}
\caption{\label{polish-alpha}PCA plot of two different polish alpha
initialisations. A default polish alpha = 0.5 searches a larger space
that is unncessary while a small customised initial value of polish
alpha will search near the ending basis. Both intialisations reach the
same ending index values.}
\end{figure}

\newpage

\hypertarget{a-comprehensive-example-of-diagnosing-a-noisy-index-function}{%
\subsection{A comprehensive example of diagnosing a noisy index
function}\label{a-comprehensive-example-of-diagnosing-a-noisy-index-function}}

The interpolation path of holes index, as seen in Figure
\ref{interruption}, is smooth, while this may not be the case for more
complicated index functions. \texttt{kol\_cdf} index, an 1D projection
index function based on Kolmogorov test, compares the difference between
the 1D projected data, \(\mathbf{P}_{n \times 1}\) and a randomly
generated normal distribution, \(y_n\) based on the empirical cumulated
distribution function (ECDF). Denotes the ECDF function as \(F(u)\) with
subscript incidating the variable, the Kolmogorove statistics defined by

\[\max \left[F_{\mathbf{P}}(u) - F_{y}(u)\right]\]

can be seen as a function of the projection matrix
\(\mathbf{A}_{p \times 1}\) and hence a valid index function.

\hypertarget{explore-index-value}{%
\subsubsection{Explore index value}\label{explore-index-value}}

Figure \ref{kol-cdf} compares the tracing plot of the interpolating
points when using different optimisation algorithms:
\texttt{search\_geodesic} and \texttt{search\_better}. One can observe
that

\begin{itemize}
\tightlist
\item
  The index value of \texttt{kol\_cdf} index is much smaller than that
  of holes index
\item
  The link of index values from interpolation bases are no longer smooth
\item
  Both algorithms reach a similar final index value after polishing
\end{itemize}

Polishing step has done much more work to find the final index value ub
\texttt{search\_geodesic} than \texttt{search\_better} and this
indicates \texttt{kol\_cdf} function favours of a random search method
than ascent method.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/kol-cdf-1.pdf}
\caption{\label{kol-cdf}Comparison of two different searching methods:
search\_geodesic and search\_better on 1D projection problem for a
noisier index: kol\_cdf. The geodesic search rely heavily on the
polishing step to find the final index value while search better works
well.}
\end{figure}

Now we enlarge the dataset to include two informative variables:
\texttt{x2} and \texttt{x3} and remain 1D projection. In this case, two
local maximum appear when projection matrix being \([0, 1, 0, 0, 0, 0]\)
and \([0, 0, 1 ,0, 0, 0]\).

Using different seeds in \texttt{search\_better} allows us to find both
local maximum as in Figure \ref{1d-2var-different-seeds}. Comparing the
maximum of both, we can see that the global maximum happens when
\texttt{x2} is found. It is natural to ask then if there is an algorithm
that can find the global maximum without trying on different seeds?
\texttt{search\_better\_random} manages to do it via a
metropolis-hasting random search as shown in Figure
\ref{1d-2var-better-random}, although at a higher cost of number of
points to evaluate.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/1d-2var-different-seeds-1.pdf}
\caption{\label{1d-2var-different-seeds}The trace plot search better in
a 1D projection problem with two informative variables using different
seeds (without polishing). Since there are two informative variables,
setting different value for seed will lead search better to find either
of the local maximum.}
\end{figure}

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/1d-2var-better-random-1.pdf}
\caption{\label{1d-2var-better-random}Using search better random for the
problem above will result in finding the global maximum but much larger
number of iteration is needed.}
\end{figure}

\hypertarget{explore-searching-space}{%
\subsubsection{Explore searching space}\label{explore-searching-space}}

We can also plot the searching points of all the three algorithms in the
searching space and explore their relative position against each other
using principal components. As shown in Figure
\ref{1d-2var-explore-proj-pca}, the bases from better1 and better2 only
search a proportion of the searching space while better\_random produces
a more exhausive search. The large overlapping of better1 and
better\_random is explained by the fact that both algorithms finds x2 in
the end.

\begin{figure}
\centering
\includegraphics{paper_files/figure-latex/1d-2var-explore-proj-pca-1.pdf}
\caption{\label{1d-2var-explore-proj-pca} The projected projection basis
using principal components. The bases from better1 and better2 only
search a proportion of the searching space while better\_random produces
a more exhausive search. The large overlapping of better1 and
better\_random is explained by the fact that both algorithms finds x2 in
the end.}
\end{figure}

\hypertarget{implementation-ferrn-pacakge}{%
\section{Implementation: Ferrn
pacakge}\label{implementation-ferrn-pacakge}}

Everything is coded up in a package. Package structure

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

\clearpage

\bibliographystyle{agsm}
\bibliography{biblio.bib}

\end{document}
